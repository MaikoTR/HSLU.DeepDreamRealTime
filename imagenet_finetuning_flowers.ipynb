{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2a4b9d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import glob\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import kagglehub\n",
    "\n",
    "\n",
    "import tarfile\n",
    "import shutil\n",
    "import scipy.io\n",
    "import random\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Lambda\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras import backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from PIL import Image\n",
    "import cv2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95dde427",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/ashfaqsyed/102-flower-dataset?dataset_version_number=1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2.35G/2.35G [01:16<00:00, 33.2MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /home/maiko/.cache/kagglehub/datasets/ashfaqsyed/102-flower-dataset/versions/1\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"ashfaqsyed/102-flower-dataset\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad78bdf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files moved to: ./data/flowers\n"
     ]
    }
   ],
   "source": [
    "target_dir = \"./data/flowers\"\n",
    "\n",
    "!mkdir -p {target_dir}\n",
    "!mv {path}/* {target_dir}/\n",
    "\n",
    "print(f\"Files moved to: {target_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1021c724",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset organized into train/val/test folders successfully.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dataset_archive = \"./data/flowers/102flowers.tgz\"\n",
    "label_file = \"./data/flowers/imagelabels.mat\"\n",
    "extracted_dir = \"./data/flowers/jpg\"  # the folder inside the .tgz\n",
    "output_dir = \"./data/flowers\"\n",
    "\n",
    "# 1. Extract the .tgz archive\n",
    "with tarfile.open(dataset_archive, \"r:gz\") as tar:\n",
    "    tar.extractall(path=output_dir)\n",
    "\n",
    "# 2. Load labels from .mat\n",
    "labels_data = scipy.io.loadmat(label_file)\n",
    "labels = labels_data['labels'][0]  # Shape (8189,)\n",
    "\n",
    "# 3. Collect all image filenames\n",
    "image_files = sorted(Path(extracted_dir).glob(\"*.jpg\"))  # Sorted by file name\n",
    "assert len(image_files) == len(labels), \"Mismatch in images and labels count\"\n",
    "\n",
    "# 4. Create label to filenames mapping\n",
    "label_to_files = {}\n",
    "for img_path, label in zip(image_files, labels):\n",
    "    class_name = f\"class_{label:03d}\"\n",
    "    label_to_files.setdefault(class_name, []).append(img_path)\n",
    "\n",
    "# 5. Split and move files into train/val/test\n",
    "def split_and_copy(label_to_files, base_dir, train_ratio=0.7, val_ratio=0.15):\n",
    "    for class_name, files in label_to_files.items():\n",
    "        random.shuffle(files)\n",
    "        n = len(files)\n",
    "        train_end = int(train_ratio * n)\n",
    "        val_end = train_end + int(val_ratio * n)\n",
    "\n",
    "        splits = {\n",
    "            \"train\": files[:train_end],\n",
    "            \"val\": files[train_end:val_end],\n",
    "            \"test\": files[val_end:]\n",
    "        }\n",
    "\n",
    "        for split, split_files in splits.items():\n",
    "            split_dir = Path(base_dir) / split / class_name\n",
    "            split_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "            for file in split_files:\n",
    "                shutil.copy(file, split_dir / file.name)\n",
    "\n",
    "split_and_copy(label_to_files, output_dir)\n",
    "\n",
    "print(\"Dataset organized into train/val/test folders successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f0cf9076",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📁 ./data/flowers\n",
      "  └── 📂 jpg\n",
      "  └── 📂 val\n",
      "  └── 📂 train\n",
      "  └── 📂 test\n",
      "  └── 📄 102flowers.tgz\n",
      "  └── 📄 imagelabels.mat\n",
      "  └── 📄 distancematrices102.mat\n",
      "  └── 📄 setid.mat\n",
      "  └── 📄 102segmentations.tgz\n",
      "\n",
      "📁 ./data/flowers/jpg\n",
      "  └── 📄 image_01404.jpg\n",
      "  └── 📄 image_05029.jpg\n",
      "  └── 📄 image_07831.jpg\n",
      "  └── 📄 image_00990.jpg\n",
      "  └── 📄 image_05751.jpg\n",
      "\n",
      "📁 ./data/flowers/val\n",
      "  └── 📂 class_029\n",
      "  └── 📂 class_027\n",
      "  └── 📂 class_013\n",
      "  └── 📂 class_001\n",
      "  └── 📂 class_024\n",
      "  └── 📂 class_102\n",
      "  └── 📂 class_032\n",
      "  └── 📂 class_078\n",
      "  └── 📂 class_054\n",
      "  └── 📂 class_093\n",
      "  └── 📂 class_047\n",
      "  └── 📂 class_007\n",
      "  └── 📂 class_071\n",
      "  └── 📂 class_030\n",
      "  └── 📂 class_044\n",
      "  └── 📂 class_086\n",
      "  └── 📂 class_083\n",
      "  └── 📂 class_080\n",
      "  └── 📂 class_070\n",
      "  └── 📂 class_046\n",
      "  └── 📂 class_049\n",
      "  └── 📂 class_088\n",
      "  └── 📂 class_063\n",
      "  └── 📂 class_012\n",
      "  └── 📂 class_066\n",
      "  └── 📂 class_031\n",
      "  └── 📂 class_056\n",
      "  └── 📂 class_068\n",
      "  └── 📂 class_101\n",
      "  └── 📂 class_079\n",
      "  └── 📂 class_091\n",
      "  └── 📂 class_011\n",
      "  └── 📂 class_099\n",
      "  └── 📂 class_022\n",
      "  └── 📂 class_003\n",
      "  └── 📂 class_008\n",
      "  └── 📂 class_045\n",
      "  └── 📂 class_051\n",
      "  └── 📂 class_021\n",
      "  └── 📂 class_090\n",
      "  └── 📂 class_089\n",
      "  └── 📂 class_016\n",
      "  └── 📂 class_087\n",
      "  └── 📂 class_058\n",
      "  └── 📂 class_040\n",
      "  └── 📂 class_034\n",
      "  └── 📂 class_053\n",
      "  └── 📂 class_025\n",
      "  └── 📂 class_028\n",
      "  └── 📂 class_043\n",
      "  └── 📂 class_010\n",
      "  └── 📂 class_018\n",
      "  └── 📂 class_100\n",
      "  └── 📂 class_026\n",
      "  └── 📂 class_074\n",
      "  └── 📂 class_023\n",
      "  └── 📂 class_085\n",
      "  └── 📂 class_081\n",
      "  └── 📂 class_019\n",
      "  └── 📂 class_052\n",
      "  └── 📂 class_035\n",
      "  └── 📂 class_094\n",
      "  └── 📂 class_092\n",
      "  └── 📂 class_076\n",
      "  └── 📂 class_075\n",
      "  └── 📂 class_055\n",
      "  └── 📂 class_098\n",
      "  └── 📂 class_072\n",
      "  └── 📂 class_060\n",
      "  └── 📂 class_084\n",
      "  └── 📂 class_064\n",
      "  └── 📂 class_096\n",
      "  └── 📂 class_069\n",
      "  └── 📂 class_050\n",
      "  └── 📂 class_065\n",
      "  └── 📂 class_017\n",
      "  └── 📂 class_005\n",
      "  └── 📂 class_033\n",
      "  └── 📂 class_059\n",
      "  └── 📂 class_039\n",
      "  └── 📂 class_041\n",
      "  └── 📂 class_067\n",
      "  └── 📂 class_036\n",
      "  └── 📂 class_082\n",
      "  └── 📂 class_015\n",
      "  └── 📂 class_062\n",
      "  └── 📂 class_097\n",
      "  └── 📂 class_009\n",
      "  └── 📂 class_037\n",
      "  └── 📂 class_006\n",
      "  └── 📂 class_057\n",
      "  └── 📂 class_002\n",
      "  └── 📂 class_014\n",
      "  └── 📂 class_042\n",
      "  └── 📂 class_095\n",
      "  └── 📂 class_038\n",
      "  └── 📂 class_077\n",
      "  └── 📂 class_004\n",
      "  └── 📂 class_048\n",
      "  └── 📂 class_020\n",
      "  └── 📂 class_061\n",
      "  └── 📂 class_073\n",
      "\n",
      "📁 ./data/flowers/val/class_029\n",
      "  └── 📄 image_04102.jpg\n",
      "  └── 📄 image_04143.jpg\n",
      "  └── 📄 image_04144.jpg\n",
      "  └── 📄 image_04084.jpg\n",
      "  └── 📄 image_04101.jpg\n",
      "\n",
      "📁 ./data/flowers/val/class_027\n",
      "  └── 📄 image_06872.jpg\n",
      "  └── 📄 image_06853.jpg\n",
      "  └── 📄 image_06852.jpg\n",
      "  └── 📄 image_06873.jpg\n",
      "  └── 📄 image_06865.jpg\n",
      "\n",
      "📁 ./data/flowers/val/class_013\n",
      "  └── 📄 image_05751.jpg\n",
      "  └── 📄 image_05764.jpg\n",
      "  └── 📄 image_05787.jpg\n",
      "  └── 📄 image_05781.jpg\n",
      "  └── 📄 image_05789.jpg\n",
      "\n",
      "📁 ./data/flowers/val/class_001\n",
      "  └── 📄 image_06765.jpg\n",
      "  └── 📄 image_06767.jpg\n",
      "  └── 📄 image_06738.jpg\n",
      "  └── 📄 image_06737.jpg\n",
      "  └── 📄 image_06744.jpg\n",
      "\n",
      "📁 ./data/flowers/val/class_024\n",
      "  └── 📄 image_08053.jpg\n",
      "  └── 📄 image_06828.jpg\n",
      "  └── 📄 image_06817.jpg\n",
      "  └── 📄 image_08048.jpg\n",
      "  └── 📄 image_06814.jpg\n",
      "\n",
      "📁 ./data/flowers/val/class_102\n",
      "  └── 📄 image_08034.jpg\n",
      "  └── 📄 image_08041.jpg\n",
      "  └── 📄 image_08003.jpg\n",
      "  └── 📄 image_08006.jpg\n",
      "  └── 📄 image_08045.jpg\n",
      "\n",
      "📁 ./data/flowers/val/class_032\n",
      "  └── 📄 image_05609.jpg\n",
      "  └── 📄 image_05625.jpg\n",
      "  └── 📄 image_05619.jpg\n",
      "  └── 📄 image_05590.jpg\n",
      "  └── 📄 image_05605.jpg\n",
      "\n",
      "📁 ./data/flowers/val/class_078\n",
      "  └── 📄 image_01838.jpg\n",
      "  └── 📄 image_01850.jpg\n",
      "  └── 📄 image_01900.jpg\n",
      "  └── 📄 image_01834.jpg\n",
      "  └── 📄 image_01915.jpg\n",
      "\n",
      "📁 ./data/flowers/val/class_054\n",
      "  └── 📄 image_05437.jpg\n",
      "  └── 📄 image_05427.jpg\n",
      "  └── 📄 image_05418.jpg\n",
      "  └── 📄 image_05432.jpg\n",
      "  └── 📄 image_05409.jpg\n",
      "\n",
      "📁 ./data/flowers/val/class_093\n",
      "  └── 📄 image_06031.jpg\n",
      "  └── 📄 image_08113.jpg\n",
      "  └── 📄 image_06019.jpg\n",
      "  └── 📄 image_06043.jpg\n",
      "  └── 📄 image_08116.jpg\n",
      "\n",
      "📁 ./data/flowers/val/class_047\n",
      "  └── 📄 image_04961.jpg\n",
      "  └── 📄 image_04999.jpg\n",
      "  └── 📄 image_04987.jpg\n",
      "  └── 📄 image_04960.jpg\n",
      "  └── 📄 image_04967.jpg\n",
      "\n",
      "📁 ./data/flowers/val/class_007\n",
      "  └── 📄 image_07219.jpg\n",
      "  └── 📄 image_08101.jpg\n",
      "  └── 📄 image_07226.jpg\n",
      "  └── 📄 image_07214.jpg\n",
      "  └── 📄 image_07202.jpg\n",
      "\n",
      "📁 ./data/flowers/val/class_071\n",
      "  └── 📄 image_04482.jpg\n",
      "  └── 📄 image_04524.jpg\n",
      "  └── 📄 image_04555.jpg\n",
      "  └── 📄 image_04512.jpg\n",
      "  └── 📄 image_04526.jpg\n",
      "\n",
      "📁 ./data/flowers/val/class_030\n",
      "  └── 📄 image_03542.jpg\n",
      "  └── 📄 image_03521.jpg\n",
      "  └── 📄 image_03528.jpg\n",
      "  └── 📄 image_03487.jpg\n",
      "  └── 📄 image_03507.jpg\n",
      "\n",
      "📁 ./data/flowers/val/class_044\n",
      "  └── 📄 image_01575.jpg\n",
      "  └── 📄 image_01504.jpg\n",
      "  └── 📄 image_01538.jpg\n",
      "  └── 📄 image_01500.jpg\n",
      "  └── 📄 image_01523.jpg\n",
      "\n",
      "📁 ./data/flowers/val/class_086\n",
      "  └── 📄 image_02895.jpg\n",
      "  └── 📄 image_02894.jpg\n",
      "  └── 📄 image_02892.jpg\n",
      "  └── 📄 image_02874.jpg\n",
      "  └── 📄 image_02880.jpg\n",
      "\n",
      "📁 ./data/flowers/val/class_083\n",
      "  └── 📄 image_01786.jpg\n",
      "  └── 📄 image_01749.jpg\n",
      "  └── 📄 image_01815.jpg\n",
      "  └── 📄 image_01817.jpg\n",
      "  └── 📄 image_01819.jpg\n",
      "\n",
      "📁 ./data/flowers/val/class_080\n",
      "  └── 📄 image_01990.jpg\n",
      "  └── 📄 image_02014.jpg\n",
      "  └── 📄 image_01967.jpg\n",
      "  └── 📄 image_02035.jpg\n",
      "  └── 📄 image_01995.jpg\n",
      "\n",
      "📁 ./data/flowers/val/class_070\n",
      "  └── 📄 image_05301.jpg\n",
      "  └── 📄 image_05308.jpg\n",
      "  └── 📄 image_05333.jpg\n",
      "  └── 📄 image_05332.jpg\n",
      "  └── 📄 image_05311.jpg\n",
      "\n",
      "📁 ./data/flowers/val/class_046\n",
      "  └── 📄 image_01014.jpg\n",
      "  └── 📄 image_01030.jpg\n",
      "  └── 📄 image_01084.jpg\n",
      "  └── 📄 image_00951.jpg\n",
      "  └── 📄 image_01008.jpg\n",
      "\n",
      "📁 ./data/flowers/val/class_049\n",
      "  └── 📄 image_06218.jpg\n",
      "  └── 📄 image_06223.jpg\n",
      "  └── 📄 image_06211.jpg\n",
      "  └── 📄 image_06207.jpg\n",
      "  └── 📄 image_06241.jpg\n",
      "\n",
      "📁 ./data/flowers/val/class_088\n",
      "  └── 📄 image_00589.jpg\n",
      "  └── 📄 image_08083.jpg\n",
      "  └── 📄 image_00577.jpg\n",
      "  └── 📄 image_00468.jpg\n",
      "  └── 📄 image_00556.jpg\n",
      "\n",
      "📁 ./data/flowers/val/class_063\n",
      "  └── 📄 image_05891.jpg\n",
      "  └── 📄 image_05875.jpg\n",
      "  └── 📄 image_05863.jpg\n",
      "  └── 📄 image_05880.jpg\n",
      "  └── 📄 image_05896.jpg\n",
      "\n",
      "📁 ./data/flowers/val/class_012\n",
      "  └── 📄 image_04060.jpg\n",
      "  └── 📄 image_04056.jpg\n",
      "  └── 📄 image_03994.jpg\n",
      "  └── 📄 image_03996.jpg\n",
      "  └── 📄 image_04028.jpg\n",
      "\n",
      "📁 ./data/flowers/val/class_066\n",
      "  └── 📄 image_05545.jpg\n",
      "  └── 📄 image_05565.jpg\n",
      "  └── 📄 image_05572.jpg\n",
      "  └── 📄 image_05527.jpg\n",
      "  └── 📄 image_05538.jpg\n",
      "\n",
      "📁 ./data/flowers/val/class_031\n",
      "  └── 📄 image_08065.jpg\n",
      "  └── 📄 image_08071.jpg\n",
      "  └── 📄 image_06902.jpg\n",
      "  └── 📄 image_06923.jpg\n",
      "  └── 📄 image_06903.jpg\n",
      "\n",
      "📁 ./data/flowers/val/class_056\n",
      "  └── 📄 image_02808.jpg\n",
      "  └── 📄 image_02844.jpg\n",
      "  └── 📄 image_02798.jpg\n",
      "  └── 📄 image_02827.jpg\n",
      "  └── 📄 image_02832.jpg\n",
      "\n",
      "📁 ./data/flowers/val/class_068\n",
      "  └── 📄 image_05922.jpg\n",
      "  └── 📄 image_05943.jpg\n",
      "  └── 📄 image_05935.jpg\n",
      "  └── 📄 image_05907.jpg\n",
      "  └── 📄 image_05903.jpg\n",
      "\n",
      "📁 ./data/flowers/val/class_101\n",
      "  └── 📄 image_07990.jpg\n",
      "  └── 📄 image_07992.jpg\n",
      "  └── 📄 image_07975.jpg\n",
      "  └── 📄 image_07954.jpg\n",
      "  └── 📄 image_07988.jpg\n",
      "\n",
      "📁 ./data/flowers/val/class_079\n",
      "  └── 📄 image_06695.jpg\n",
      "  └── 📄 image_06711.jpg\n",
      "  └── 📄 image_06724.jpg\n",
      "  └── 📄 image_06733.jpg\n",
      "  └── 📄 image_06706.jpg\n",
      "\n",
      "📁 ./data/flowers/val/class_091\n",
      "  └── 📄 image_04856.jpg\n",
      "  └── 📄 image_04875.jpg\n",
      "  └── 📄 image_04880.jpg\n",
      "  └── 📄 image_04855.jpg\n",
      "  └── 📄 image_04851.jpg\n",
      "\n",
      "📁 ./data/flowers/val/class_011\n",
      "  └── 📄 image_03141.jpg\n",
      "  └── 📄 image_03106.jpg\n",
      "  └── 📄 image_03119.jpg\n",
      "  └── 📄 image_03122.jpg\n",
      "  └── 📄 image_03155.jpg\n",
      "\n",
      "📁 ./data/flowers/val/class_099\n",
      "  └── 📄 image_07892.jpg\n",
      "  └── 📄 image_07842.jpg\n",
      "  └── 📄 image_07843.jpg\n",
      "  └── 📄 image_07849.jpg\n",
      "  └── 📄 image_07872.jpg\n",
      "\n",
      "📁 ./data/flowers/val/class_022\n",
      "  └── 📄 image_05364.jpg\n",
      "  └── 📄 image_05395.jpg\n",
      "  └── 📄 image_05368.jpg\n",
      "  └── 📄 image_05393.jpg\n",
      "  └── 📄 image_05351.jpg\n",
      "\n",
      "📁 ./data/flowers/val/class_003\n",
      "  └── 📄 image_06616.jpg\n",
      "  └── 📄 image_06637.jpg\n",
      "  └── 📄 image_06640.jpg\n",
      "  └── 📄 image_06622.jpg\n",
      "  └── 📄 image_06651.jpg\n",
      "\n",
      "📁 ./data/flowers/val/class_008\n",
      "  └── 📄 image_03356.jpg\n",
      "  └── 📄 image_03290.jpg\n",
      "  └── 📄 image_03312.jpg\n",
      "  └── 📄 image_03344.jpg\n",
      "  └── 📄 image_03303.jpg\n",
      "\n",
      "📁 ./data/flowers/val/class_045\n",
      "  └── 📄 image_08098.jpg\n",
      "  └── 📄 image_07132.jpg\n",
      "  └── 📄 image_07125.jpg\n",
      "  └── 📄 image_07127.jpg\n",
      "  └── 📄 image_07130.jpg\n",
      "\n",
      "📁 ./data/flowers/val/class_051\n",
      "  └── 📄 image_03916.jpg\n",
      "  └── 📄 image_01408.jpg\n",
      "  └── 📄 image_01484.jpg\n",
      "  └── 📄 image_03923.jpg\n",
      "  └── 📄 image_01332.jpg\n",
      "\n",
      "📁 ./data/flowers/val/class_021\n",
      "  └── 📄 image_06785.jpg\n",
      "  └── 📄 image_06804.jpg\n",
      "  └── 📄 image_06775.jpg\n",
      "  └── 📄 image_06789.jpg\n",
      "  └── 📄 image_06783.jpg\n",
      "\n",
      "📁 ./data/flowers/val/class_090\n",
      "  └── 📄 image_04418.jpg\n",
      "  └── 📄 image_04438.jpg\n",
      "  └── 📄 image_04471.jpg\n",
      "  └── 📄 image_04480.jpg\n",
      "  └── 📄 image_04479.jpg\n",
      "\n",
      "📁 ./data/flowers/val/class_089\n",
      "  └── 📄 image_00766.jpg\n",
      "  └── 📄 image_00633.jpg\n",
      "  └── 📄 image_00675.jpg\n",
      "  └── 📄 image_00769.jpg\n",
      "  └── 📄 image_00660.jpg\n",
      "\n",
      "📁 ./data/flowers/val/class_016\n",
      "  └── 📄 image_06661.jpg\n",
      "  └── 📄 image_06679.jpg\n",
      "  └── 📄 image_06686.jpg\n",
      "  └── 📄 image_06678.jpg\n",
      "  └── 📄 image_06668.jpg\n",
      "\n",
      "📁 ./data/flowers/val/class_087\n",
      "  └── 📄 image_05483.jpg\n",
      "  └── 📄 image_05465.jpg\n",
      "  └── 📄 image_05474.jpg\n",
      "  └── 📄 image_05502.jpg\n",
      "  └── 📄 image_05460.jpg\n",
      "\n",
      "📁 ./data/flowers/val/class_058\n",
      "  └── 📄 image_02716.jpg\n",
      "  └── 📄 image_02737.jpg\n",
      "  └── 📄 image_02693.jpg\n",
      "  └── 📄 image_02742.jpg\n",
      "  └── 📄 image_02674.jpg\n",
      "\n",
      "📁 ./data/flowers/val/class_040\n",
      "  └── 📄 image_04577.jpg\n",
      "  └── 📄 image_04591.jpg\n",
      "  └── 📄 image_04596.jpg\n",
      "  └── 📄 image_04615.jpg\n",
      "  └── 📄 image_04600.jpg\n",
      "\n",
      "📁 ./data/flowers/val/class_034\n",
      "  └── 📄 image_06931.jpg\n",
      "  └── 📄 image_06965.jpg\n",
      "  └── 📄 image_06954.jpg\n",
      "  └── 📄 image_06953.jpg\n",
      "  └── 📄 image_06944.jpg\n",
      "\n",
      "📁 ./data/flowers/val/class_053\n",
      "  └── 📄 image_03665.jpg\n",
      "  └── 📄 image_03659.jpg\n",
      "  └── 📄 image_03656.jpg\n",
      "  └── 📄 image_03661.jpg\n",
      "  └── 📄 image_03684.jpg\n",
      "\n",
      "📁 ./data/flowers/val/class_025\n",
      "  └── 📄 image_06590.jpg\n",
      "  └── 📄 image_06572.jpg\n",
      "  └── 📄 image_06582.jpg\n",
      "  └── 📄 image_06598.jpg\n",
      "  └── 📄 image_06611.jpg\n",
      "\n",
      "📁 ./data/flowers/val/class_028\n",
      "  └── 📄 image_05242.jpg\n",
      "  └── 📄 image_05250.jpg\n",
      "  └── 📄 image_05277.jpg\n",
      "  └── 📄 image_05213.jpg\n",
      "  └── 📄 image_05258.jpg\n",
      "\n",
      "📁 ./data/flowers/val/class_043\n",
      "  └── 📄 image_02393.jpg\n",
      "  └── 📄 image_02317.jpg\n",
      "  └── 📄 image_02349.jpg\n",
      "  └── 📄 image_02326.jpg\n",
      "  └── 📄 image_02436.jpg\n",
      "\n",
      "📁 ./data/flowers/val/class_010\n",
      "  └── 📄 image_07109.jpg\n",
      "  └── 📄 image_07097.jpg\n",
      "  └── 📄 image_07106.jpg\n",
      "  └── 📄 image_07088.jpg\n",
      "  └── 📄 image_07118.jpg\n",
      "\n",
      "📁 ./data/flowers/val/class_018\n",
      "  └── 📄 image_04279.jpg\n",
      "  └── 📄 image_04281.jpg\n",
      "  └── 📄 image_04286.jpg\n",
      "  └── 📄 image_04278.jpg\n",
      "  └── 📄 image_04289.jpg\n",
      "\n",
      "📁 ./data/flowers/val/class_100\n",
      "  └── 📄 image_07939.jpg\n",
      "  └── 📄 image_07912.jpg\n",
      "  └── 📄 image_07914.jpg\n",
      "  └── 📄 image_07899.jpg\n",
      "  └── 📄 image_07938.jpg\n",
      "\n",
      "📁 ./data/flowers/val/class_026\n",
      "  └── 📄 image_06495.jpg\n",
      "  └── 📄 image_06487.jpg\n",
      "  └── 📄 image_06516.jpg\n",
      "  └── 📄 image_06511.jpg\n",
      "  └── 📄 image_06503.jpg\n",
      "\n",
      "📁 ./data/flowers/val/class_074\n",
      "  └── 📄 image_01293.jpg\n",
      "  └── 📄 image_01247.jpg\n",
      "  └── 📄 image_01292.jpg\n",
      "  └── 📄 image_01289.jpg\n",
      "  └── 📄 image_01287.jpg\n",
      "\n",
      "📁 ./data/flowers/val/class_023\n",
      "  └── 📄 image_03410.jpg\n",
      "  └── 📄 image_03373.jpg\n",
      "  └── 📄 image_03388.jpg\n",
      "  └── 📄 image_03431.jpg\n",
      "  └── 📄 image_03376.jpg\n",
      "\n",
      "📁 ./data/flowers/val/class_085\n",
      "  └── 📄 image_04798.jpg\n",
      "  └── 📄 image_04782.jpg\n",
      "  └── 📄 image_04769.jpg\n",
      "  └── 📄 image_04797.jpg\n",
      "  └── 📄 image_04821.jpg\n",
      "\n",
      "📁 ./data/flowers/val/class_081\n",
      "  └── 📄 image_00920.jpg\n",
      "  └── 📄 image_00889.jpg\n",
      "  └── 📄 image_00938.jpg\n",
      "  └── 📄 image_00786.jpg\n",
      "  └── 📄 image_00857.jpg\n",
      "\n",
      "📁 ./data/flowers/val/class_019\n",
      "  └── 📄 image_06190.jpg\n",
      "  └── 📄 image_06151.jpg\n",
      "  └── 📄 image_06177.jpg\n",
      "  └── 📄 image_06197.jpg\n",
      "  └── 📄 image_06172.jpg\n",
      "\n",
      "📁 ./data/flowers/val/class_052\n",
      "  └── 📄 image_04219.jpg\n",
      "  └── 📄 image_04235.jpg\n",
      "  └── 📄 image_04186.jpg\n",
      "  └── 📄 image_04204.jpg\n",
      "  └── 📄 image_04208.jpg\n",
      "\n",
      "📁 ./data/flowers/val/class_035\n",
      "  └── 📄 image_06981.jpg\n",
      "  └── 📄 image_06996.jpg\n",
      "  └── 📄 image_08084.jpg\n",
      "  └── 📄 image_08087.jpg\n",
      "  └── 📄 image_08088.jpg\n",
      "\n",
      "📁 ./data/flowers/val/class_094\n",
      "  └── 📄 image_07352.jpg\n",
      "  └── 📄 image_07368.jpg\n",
      "  └── 📄 image_07421.jpg\n",
      "  └── 📄 image_07361.jpg\n",
      "  └── 📄 image_07329.jpg\n",
      "\n",
      "📁 ./data/flowers/val/class_092\n",
      "  └── 📄 image_03085.jpg\n",
      "  └── 📄 image_03072.jpg\n",
      "  └── 📄 image_03089.jpg\n",
      "  └── 📄 image_03036.jpg\n",
      "  └── 📄 image_03035.jpg\n",
      "\n",
      "📁 ./data/flowers/val/class_076\n",
      "  └── 📄 image_02466.jpg\n",
      "  └── 📄 image_02457.jpg\n",
      "  └── 📄 image_02479.jpg\n",
      "  └── 📄 image_02507.jpg\n",
      "  └── 📄 image_02487.jpg\n",
      "\n",
      "📁 ./data/flowers/val/class_075\n",
      "  └── 📄 image_02093.jpg\n",
      "  └── 📄 image_02174.jpg\n",
      "  └── 📄 image_02118.jpg\n",
      "  └── 📄 image_02150.jpg\n",
      "  └── 📄 image_02110.jpg\n",
      "\n",
      "📁 ./data/flowers/val/class_055\n",
      "  └── 📄 image_04735.jpg\n",
      "  └── 📄 image_04703.jpg\n",
      "  └── 📄 image_04698.jpg\n",
      "  └── 📄 image_04764.jpg\n",
      "  └── 📄 image_04737.jpg\n",
      "\n",
      "📁 ./data/flowers/val/class_098\n",
      "  └── 📄 image_07763.jpg\n",
      "  └── 📄 image_07766.jpg\n",
      "  └── 📄 image_07758.jpg\n",
      "  └── 📄 image_07762.jpg\n",
      "  └── 📄 image_07825.jpg\n",
      "\n",
      "📁 ./data/flowers/val/class_072\n",
      "  └── 📄 image_03584.jpg\n",
      "  └── 📄 image_03553.jpg\n",
      "  └── 📄 image_03587.jpg\n",
      "  └── 📄 image_03611.jpg\n",
      "  └── 📄 image_03620.jpg\n",
      "\n",
      "📁 ./data/flowers/val/class_060\n",
      "  └── 📄 image_02934.jpg\n",
      "  └── 📄 image_02954.jpg\n",
      "  └── 📄 image_02971.jpg\n",
      "  └── 📄 image_03017.jpg\n",
      "  └── 📄 image_02956.jpg\n",
      "\n",
      "📁 ./data/flowers/val/class_084\n",
      "  └── 📄 image_02586.jpg\n",
      "  └── 📄 image_02620.jpg\n",
      "  └── 📄 image_02569.jpg\n",
      "  └── 📄 image_02596.jpg\n",
      "  └── 📄 image_02632.jpg\n",
      "\n",
      "📁 ./data/flowers/val/class_064\n",
      "  └── 📄 image_06111.jpg\n",
      "  └── 📄 image_06112.jpg\n",
      "  └── 📄 image_06122.jpg\n",
      "  └── 📄 image_06140.jpg\n",
      "  └── 📄 image_06102.jpg\n",
      "\n",
      "📁 ./data/flowers/val/class_096\n",
      "  └── 📄 image_07607.jpg\n",
      "  └── 📄 image_07662.jpg\n",
      "  └── 📄 image_07611.jpg\n",
      "  └── 📄 image_07615.jpg\n",
      "  └── 📄 image_07664.jpg\n",
      "\n",
      "📁 ./data/flowers/val/class_069\n",
      "  └── 📄 image_06009.jpg\n",
      "  └── 📄 image_05996.jpg\n",
      "  └── 📄 image_05988.jpg\n",
      "  └── 📄 image_06007.jpg\n",
      "  └── 📄 image_06003.jpg\n",
      "\n",
      "📁 ./data/flowers/val/class_050\n",
      "  └── 📄 image_06561.jpg\n",
      "  └── 📄 image_06565.jpg\n",
      "  └── 📄 image_06299.jpg\n",
      "  └── 📄 image_06329.jpg\n",
      "  └── 📄 image_06323.jpg\n",
      "\n",
      "📁 ./data/flowers/val/class_065\n",
      "  └── 📄 image_03278.jpg\n",
      "  └── 📄 image_03271.jpg\n",
      "  └── 📄 image_03200.jpg\n",
      "  └── 📄 image_03233.jpg\n",
      "  └── 📄 image_03258.jpg\n",
      "\n",
      "📁 ./data/flowers/val/class_017\n",
      "  └── 📄 image_03910.jpg\n",
      "  └── 📄 image_03899.jpg\n",
      "  └── 📄 image_03850.jpg\n",
      "  └── 📄 image_03892.jpg\n",
      "  └── 📄 image_03902.jpg\n",
      "\n",
      "📁 ./data/flowers/val/class_005\n",
      "  └── 📄 image_05158.jpg\n",
      "  └── 📄 image_05180.jpg\n",
      "  └── 📄 image_05207.jpg\n",
      "  └── 📄 image_05171.jpg\n",
      "  └── 📄 image_05160.jpg\n",
      "\n",
      "📁 ./data/flowers/val/class_033\n",
      "  └── 📄 image_06443.jpg\n",
      "  └── 📄 image_06454.jpg\n",
      "  └── 📄 image_06456.jpg\n",
      "  └── 📄 image_06483.jpg\n",
      "  └── 📄 image_06452.jpg\n",
      "\n",
      "📁 ./data/flowers/val/class_059\n",
      "  └── 📄 image_05040.jpg\n",
      "  └── 📄 image_05072.jpg\n",
      "  └── 📄 image_05067.jpg\n",
      "  └── 📄 image_05039.jpg\n",
      "  └── 📄 image_05058.jpg\n",
      "\n",
      "📁 ./data/flowers/val/class_039\n",
      "  └── 📄 image_07020.jpg\n",
      "  └── 📄 image_07027.jpg\n",
      "  └── 📄 image_07010.jpg\n",
      "  └── 📄 image_07013.jpg\n",
      "  └── 📄 image_08080.jpg\n",
      "\n",
      "📁 ./data/flowers/val/class_041\n",
      "  └── 📄 image_02283.jpg\n",
      "  └── 📄 image_02291.jpg\n",
      "  └── 📄 image_02301.jpg\n",
      "  └── 📄 image_02231.jpg\n",
      "  └── 📄 image_02296.jpg\n",
      "\n",
      "📁 ./data/flowers/val/class_067\n",
      "  └── 📄 image_07055.jpg\n",
      "  └── 📄 image_07083.jpg\n",
      "  └── 📄 image_08078.jpg\n",
      "  └── 📄 image_07077.jpg\n",
      "  └── 📄 image_07081.jpg\n",
      "\n",
      "📁 ./data/flowers/val/class_036\n",
      "  └── 📄 image_04361.jpg\n",
      "  └── 📄 image_04345.jpg\n",
      "  └── 📄 image_04335.jpg\n",
      "  └── 📄 image_04355.jpg\n",
      "  └── 📄 image_04330.jpg\n",
      "\n",
      "📁 ./data/flowers/val/class_082\n",
      "  └── 📄 image_01640.jpg\n",
      "  └── 📄 image_01593.jpg\n",
      "  └── 📄 image_01654.jpg\n",
      "  └── 📄 image_01663.jpg\n",
      "  └── 📄 image_01672.jpg\n",
      "\n",
      "📁 ./data/flowers/val/class_015\n",
      "  └── 📄 image_06392.jpg\n",
      "  └── 📄 image_06353.jpg\n",
      "  └── 📄 image_06375.jpg\n",
      "  └── 📄 image_06347.jpg\n",
      "  └── 📄 image_06386.jpg\n",
      "\n",
      "📁 ./data/flowers/val/class_062\n",
      "  └── 📄 image_08180.jpg\n",
      "  └── 📄 image_08168.jpg\n",
      "  └── 📄 image_07282.jpg\n",
      "  └── 📄 image_08176.jpg\n",
      "  └── 📄 image_07272.jpg\n",
      "\n",
      "📁 ./data/flowers/val/class_097\n",
      "  └── 📄 image_07730.jpg\n",
      "  └── 📄 image_07688.jpg\n",
      "  └── 📄 image_07692.jpg\n",
      "  └── 📄 image_07708.jpg\n",
      "  └── 📄 image_07712.jpg\n",
      "\n",
      "📁 ./data/flowers/val/class_009\n",
      "  └── 📄 image_06419.jpg\n",
      "  └── 📄 image_06413.jpg\n",
      "  └── 📄 image_06429.jpg\n",
      "  └── 📄 image_06439.jpg\n",
      "  └── 📄 image_06422.jpg\n",
      "\n",
      "📁 ./data/flowers/val/class_037\n",
      "  └── 📄 image_03758.jpg\n",
      "  └── 📄 image_03803.jpg\n",
      "  └── 📄 image_07291.jpg\n",
      "  └── 📄 image_03792.jpg\n",
      "  └── 📄 image_03734.jpg\n",
      "\n",
      "📁 ./data/flowers/val/class_006\n",
      "  └── 📄 image_07175.jpg\n",
      "  └── 📄 image_08105.jpg\n",
      "  └── 📄 image_08106.jpg\n",
      "  └── 📄 image_07189.jpg\n",
      "  └── 📄 image_07185.jpg\n",
      "\n",
      "📁 ./data/flowers/val/class_057\n",
      "  └── 📄 image_07255.jpg\n",
      "  └── 📄 image_08118.jpg\n",
      "  └── 📄 image_08141.jpg\n",
      "  └── 📄 image_07238.jpg\n",
      "  └── 📄 image_07240.jpg\n",
      "\n",
      "📁 ./data/flowers/val/class_002\n",
      "  └── 📄 image_05143.jpg\n",
      "  └── 📄 image_05126.jpg\n",
      "  └── 📄 image_05123.jpg\n",
      "  └── 📄 image_05098.jpg\n",
      "  └── 📄 image_05106.jpg\n",
      "\n",
      "📁 ./data/flowers/val/class_014\n",
      "  └── 📄 image_06092.jpg\n",
      "  └── 📄 image_06084.jpg\n",
      "  └── 📄 image_06059.jpg\n",
      "  └── 📄 image_06080.jpg\n",
      "  └── 📄 image_06073.jpg\n",
      "\n",
      "📁 ./data/flowers/val/class_042\n",
      "  └── 📄 image_05689.jpg\n",
      "  └── 📄 image_05709.jpg\n",
      "  └── 📄 image_05737.jpg\n",
      "  └── 📄 image_05719.jpg\n",
      "  └── 📄 image_05729.jpg\n",
      "\n",
      "📁 ./data/flowers/val/class_095\n",
      "  └── 📄 image_07473.jpg\n",
      "  └── 📄 image_07573.jpg\n",
      "  └── 📄 image_07537.jpg\n",
      "  └── 📄 image_07485.jpg\n",
      "  └── 📄 image_07579.jpg\n",
      "\n",
      "📁 ./data/flowers/val/class_038\n",
      "  └── 📄 image_05797.jpg\n",
      "  └── 📄 image_05799.jpg\n",
      "  └── 📄 image_05842.jpg\n",
      "  └── 📄 image_05803.jpg\n",
      "  └── 📄 image_05830.jpg\n",
      "\n",
      "📁 ./data/flowers/val/class_077\n",
      "  └── 📄 image_00046.jpg\n",
      "  └── 📄 image_00207.jpg\n",
      "  └── 📄 image_00217.jpg\n",
      "  └── 📄 image_00113.jpg\n",
      "  └── 📄 image_00126.jpg\n",
      "\n",
      "📁 ./data/flowers/val/class_004\n",
      "  └── 📄 image_05682.jpg\n",
      "  └── 📄 image_05649.jpg\n",
      "  └── 📄 image_05643.jpg\n",
      "  └── 📄 image_05662.jpg\n",
      "  └── 📄 image_05648.jpg\n",
      "\n",
      "📁 ./data/flowers/val/class_048\n",
      "  └── 📄 image_04661.jpg\n",
      "  └── 📄 image_04695.jpg\n",
      "  └── 📄 image_04677.jpg\n",
      "  └── 📄 image_04690.jpg\n",
      "  └── 📄 image_04675.jpg\n",
      "\n",
      "📁 ./data/flowers/val/class_020\n",
      "  └── 📄 image_04941.jpg\n",
      "  └── 📄 image_04950.jpg\n",
      "  └── 📄 image_04936.jpg\n",
      "  └── 📄 image_04946.jpg\n",
      "  └── 📄 image_04927.jpg\n",
      "\n",
      "📁 ./data/flowers/val/class_061\n",
      "  └── 📄 image_06267.jpg\n",
      "  └── 📄 image_06257.jpg\n",
      "  └── 📄 image_06282.jpg\n",
      "  └── 📄 image_06247.jpg\n",
      "  └── 📄 image_06251.jpg\n",
      "\n",
      "📁 ./data/flowers/val/class_073\n",
      "  └── 📄 image_00378.jpg\n",
      "  └── 📄 image_00392.jpg\n",
      "  └── 📄 image_00303.jpg\n",
      "  └── 📄 image_00412.jpg\n",
      "  └── 📄 image_00313.jpg\n",
      "\n",
      "📁 ./data/flowers/train\n",
      "  └── 📂 class_029\n",
      "  └── 📂 class_027\n",
      "  └── 📂 class_013\n",
      "  └── 📂 class_001\n",
      "  └── 📂 class_024\n",
      "  └── 📂 class_102\n",
      "  └── 📂 class_032\n",
      "  └── 📂 class_078\n",
      "  └── 📂 class_054\n",
      "  └── 📂 class_093\n",
      "  └── 📂 class_047\n",
      "  └── 📂 class_007\n",
      "  └── 📂 class_071\n",
      "  └── 📂 class_030\n",
      "  └── 📂 class_044\n",
      "  └── 📂 class_086\n",
      "  └── 📂 class_083\n",
      "  └── 📂 class_080\n",
      "  └── 📂 class_070\n",
      "  └── 📂 class_046\n",
      "  └── 📂 class_049\n",
      "  └── 📂 class_088\n",
      "  └── 📂 class_063\n",
      "  └── 📂 class_012\n",
      "  └── 📂 class_066\n",
      "  └── 📂 class_031\n",
      "  └── 📂 class_056\n",
      "  └── 📂 class_068\n",
      "  └── 📂 class_101\n",
      "  └── 📂 class_079\n",
      "  └── 📂 class_091\n",
      "  └── 📂 class_011\n",
      "  └── 📂 class_099\n",
      "  └── 📂 class_022\n",
      "  └── 📂 class_003\n",
      "  └── 📂 class_008\n",
      "  └── 📂 class_045\n",
      "  └── 📂 class_051\n",
      "  └── 📂 class_021\n",
      "  └── 📂 class_090\n",
      "  └── 📂 class_089\n",
      "  └── 📂 class_016\n",
      "  └── 📂 class_087\n",
      "  └── 📂 class_058\n",
      "  └── 📂 class_040\n",
      "  └── 📂 class_034\n",
      "  └── 📂 class_053\n",
      "  └── 📂 class_025\n",
      "  └── 📂 class_028\n",
      "  └── 📂 class_043\n",
      "  └── 📂 class_010\n",
      "  └── 📂 class_018\n",
      "  └── 📂 class_100\n",
      "  └── 📂 class_026\n",
      "  └── 📂 class_074\n",
      "  └── 📂 class_023\n",
      "  └── 📂 class_085\n",
      "  └── 📂 class_081\n",
      "  └── 📂 class_019\n",
      "  └── 📂 class_052\n",
      "  └── 📂 class_035\n",
      "  └── 📂 class_094\n",
      "  └── 📂 class_092\n",
      "  └── 📂 class_076\n",
      "  └── 📂 class_075\n",
      "  └── 📂 class_055\n",
      "  └── 📂 class_098\n",
      "  └── 📂 class_072\n",
      "  └── 📂 class_060\n",
      "  └── 📂 class_084\n",
      "  └── 📂 class_064\n",
      "  └── 📂 class_096\n",
      "  └── 📂 class_069\n",
      "  └── 📂 class_050\n",
      "  └── 📂 class_065\n",
      "  └── 📂 class_017\n",
      "  └── 📂 class_005\n",
      "  └── 📂 class_033\n",
      "  └── 📂 class_059\n",
      "  └── 📂 class_039\n",
      "  └── 📂 class_041\n",
      "  └── 📂 class_067\n",
      "  └── 📂 class_036\n",
      "  └── 📂 class_082\n",
      "  └── 📂 class_015\n",
      "  └── 📂 class_062\n",
      "  └── 📂 class_097\n",
      "  └── 📂 class_009\n",
      "  └── 📂 class_037\n",
      "  └── 📂 class_006\n",
      "  └── 📂 class_057\n",
      "  └── 📂 class_002\n",
      "  └── 📂 class_014\n",
      "  └── 📂 class_042\n",
      "  └── 📂 class_095\n",
      "  └── 📂 class_038\n",
      "  └── 📂 class_077\n",
      "  └── 📂 class_004\n",
      "  └── 📂 class_048\n",
      "  └── 📂 class_020\n",
      "  └── 📂 class_061\n",
      "  └── 📂 class_073\n",
      "\n",
      "📁 ./data/flowers/train/class_029\n",
      "  └── 📄 image_04099.jpg\n",
      "  └── 📄 image_04151.jpg\n",
      "  └── 📄 image_04125.jpg\n",
      "  └── 📄 image_04141.jpg\n",
      "  └── 📄 image_04103.jpg\n",
      "\n",
      "📁 ./data/flowers/train/class_027\n",
      "  └── 📄 image_06863.jpg\n",
      "  └── 📄 image_06889.jpg\n",
      "  └── 📄 image_06857.jpg\n",
      "  └── 📄 image_06868.jpg\n",
      "  └── 📄 image_06851.jpg\n",
      "\n",
      "📁 ./data/flowers/train/class_013\n",
      "  └── 📄 image_05744.jpg\n",
      "  └── 📄 image_05773.jpg\n",
      "  └── 📄 image_05776.jpg\n",
      "  └── 📄 image_05756.jpg\n",
      "  └── 📄 image_05749.jpg\n",
      "\n",
      "📁 ./data/flowers/train/class_001\n",
      "  └── 📄 image_06749.jpg\n",
      "  └── 📄 image_06745.jpg\n",
      "  └── 📄 image_06759.jpg\n",
      "  └── 📄 image_06752.jpg\n",
      "  └── 📄 image_06771.jpg\n",
      "\n",
      "📁 ./data/flowers/train/class_024\n",
      "  └── 📄 image_06830.jpg\n",
      "  └── 📄 image_06815.jpg\n",
      "  └── 📄 image_06841.jpg\n",
      "  └── 📄 image_06820.jpg\n",
      "  └── 📄 image_06829.jpg\n",
      "\n",
      "📁 ./data/flowers/train/class_102\n",
      "  └── 📄 image_08019.jpg\n",
      "  └── 📄 image_08005.jpg\n",
      "  └── 📄 image_08039.jpg\n",
      "  └── 📄 image_08046.jpg\n",
      "  └── 📄 image_08031.jpg\n",
      "\n",
      "📁 ./data/flowers/train/class_032\n",
      "  └── 📄 image_05602.jpg\n",
      "  └── 📄 image_05614.jpg\n",
      "  └── 📄 image_05613.jpg\n",
      "  └── 📄 image_05588.jpg\n",
      "  └── 📄 image_05628.jpg\n",
      "\n",
      "📁 ./data/flowers/train/class_078\n",
      "  └── 📄 image_01868.jpg\n",
      "  └── 📄 image_01953.jpg\n",
      "  └── 📄 image_01872.jpg\n",
      "  └── 📄 image_01874.jpg\n",
      "  └── 📄 image_01959.jpg\n",
      "\n",
      "📁 ./data/flowers/train/class_054\n",
      "  └── 📄 image_05438.jpg\n",
      "  └── 📄 image_05448.jpg\n",
      "  └── 📄 image_05408.jpg\n",
      "  └── 📄 image_05444.jpg\n",
      "  └── 📄 image_05402.jpg\n",
      "\n",
      "📁 ./data/flowers/train/class_093\n",
      "  └── 📄 image_06016.jpg\n",
      "  └── 📄 image_06029.jpg\n",
      "  └── 📄 image_06037.jpg\n",
      "  └── 📄 image_06024.jpg\n",
      "  └── 📄 image_06011.jpg\n",
      "\n",
      "📁 ./data/flowers/train/class_047\n",
      "  └── 📄 image_05000.jpg\n",
      "  └── 📄 image_05004.jpg\n",
      "  └── 📄 image_04984.jpg\n",
      "  └── 📄 image_04966.jpg\n",
      "  └── 📄 image_04998.jpg\n",
      "\n",
      "📁 ./data/flowers/train/class_007\n",
      "  └── 📄 image_07222.jpg\n",
      "  └── 📄 image_07221.jpg\n",
      "  └── 📄 image_07205.jpg\n",
      "  └── 📄 image_07228.jpg\n",
      "  └── 📄 image_07216.jpg\n",
      "\n",
      "📁 ./data/flowers/train/class_071\n",
      "  └── 📄 image_04502.jpg\n",
      "  └── 📄 image_04545.jpg\n",
      "  └── 📄 image_04536.jpg\n",
      "  └── 📄 image_04529.jpg\n",
      "  └── 📄 image_04496.jpg\n",
      "\n",
      "📁 ./data/flowers/train/class_030\n",
      "  └── 📄 image_03524.jpg\n",
      "  └── 📄 image_03505.jpg\n",
      "  └── 📄 image_03540.jpg\n",
      "  └── 📄 image_03511.jpg\n",
      "  └── 📄 image_03514.jpg\n",
      "\n",
      "📁 ./data/flowers/train/class_044\n",
      "  └── 📄 image_01557.jpg\n",
      "  └── 📄 image_01506.jpg\n",
      "  └── 📄 image_01516.jpg\n",
      "  └── 📄 image_01492.jpg\n",
      "  └── 📄 image_01561.jpg\n",
      "\n",
      "📁 ./data/flowers/train/class_086\n",
      "  └── 📄 image_02875.jpg\n",
      "  └── 📄 image_02910.jpg\n",
      "  └── 📄 image_02899.jpg\n",
      "  └── 📄 image_02915.jpg\n",
      "  └── 📄 image_02900.jpg\n",
      "\n",
      "📁 ./data/flowers/train/class_083\n",
      "  └── 📄 image_01752.jpg\n",
      "  └── 📄 image_01794.jpg\n",
      "  └── 📄 image_01757.jpg\n",
      "  └── 📄 image_01712.jpg\n",
      "  └── 📄 image_01779.jpg\n",
      "\n",
      "📁 ./data/flowers/train/class_080\n",
      "  └── 📄 image_02054.jpg\n",
      "  └── 📄 image_02012.jpg\n",
      "  └── 📄 image_02048.jpg\n",
      "  └── 📄 image_02021.jpg\n",
      "  └── 📄 image_02053.jpg\n",
      "\n",
      "📁 ./data/flowers/train/class_070\n",
      "  └── 📄 image_05282.jpg\n",
      "  └── 📄 image_05294.jpg\n",
      "  └── 📄 image_05339.jpg\n",
      "  └── 📄 image_05320.jpg\n",
      "  └── 📄 image_05288.jpg\n",
      "\n",
      "📁 ./data/flowers/train/class_046\n",
      "  └── 📄 image_01048.jpg\n",
      "  └── 📄 image_01039.jpg\n",
      "  └── 📄 image_01137.jpg\n",
      "  └── 📄 image_01088.jpg\n",
      "  └── 📄 image_01053.jpg\n",
      "\n",
      "📁 ./data/flowers/train/class_049\n",
      "  └── 📄 image_06246.jpg\n",
      "  └── 📄 image_06243.jpg\n",
      "  └── 📄 image_06205.jpg\n",
      "  └── 📄 image_06201.jpg\n",
      "  └── 📄 image_06203.jpg\n",
      "\n",
      "📁 ./data/flowers/train/class_088\n",
      "  └── 📄 image_00515.jpg\n",
      "  └── 📄 image_00498.jpg\n",
      "  └── 📄 image_00586.jpg\n",
      "  └── 📄 image_00477.jpg\n",
      "  └── 📄 image_00482.jpg\n",
      "\n",
      "📁 ./data/flowers/train/class_063\n",
      "  └── 📄 image_05892.jpg\n",
      "  └── 📄 image_05877.jpg\n",
      "  └── 📄 image_05888.jpg\n",
      "  └── 📄 image_05884.jpg\n",
      "  └── 📄 image_05854.jpg\n",
      "\n",
      "📁 ./data/flowers/train/class_012\n",
      "  └── 📄 image_04039.jpg\n",
      "  └── 📄 image_04073.jpg\n",
      "  └── 📄 image_04016.jpg\n",
      "  └── 📄 image_03999.jpg\n",
      "  └── 📄 image_03998.jpg\n",
      "\n",
      "📁 ./data/flowers/train/class_066\n",
      "  └── 📄 image_05566.jpg\n",
      "  └── 📄 image_05535.jpg\n",
      "  └── 📄 image_05579.jpg\n",
      "  └── 📄 image_05574.jpg\n",
      "  └── 📄 image_05540.jpg\n",
      "\n",
      "📁 ./data/flowers/train/class_031\n",
      "  └── 📄 image_06928.jpg\n",
      "  └── 📄 image_06919.jpg\n",
      "  └── 📄 image_08073.jpg\n",
      "  └── 📄 image_06908.jpg\n",
      "  └── 📄 image_06894.jpg\n",
      "\n",
      "📁 ./data/flowers/train/class_056\n",
      "  └── 📄 image_02804.jpg\n",
      "  └── 📄 image_02780.jpg\n",
      "  └── 📄 image_02757.jpg\n",
      "  └── 📄 image_02792.jpg\n",
      "  └── 📄 image_02811.jpg\n",
      "\n",
      "📁 ./data/flowers/train/class_068\n",
      "  └── 📄 image_05954.jpg\n",
      "  └── 📄 image_05924.jpg\n",
      "  └── 📄 image_05931.jpg\n",
      "  └── 📄 image_05947.jpg\n",
      "  └── 📄 image_05918.jpg\n",
      "\n",
      "📁 ./data/flowers/train/class_101\n",
      "  └── 📄 image_07973.jpg\n",
      "  └── 📄 image_07968.jpg\n",
      "  └── 📄 image_07978.jpg\n",
      "  └── 📄 image_07969.jpg\n",
      "  └── 📄 image_07944.jpg\n",
      "\n",
      "📁 ./data/flowers/train/class_079\n",
      "  └── 📄 image_06707.jpg\n",
      "  └── 📄 image_06702.jpg\n",
      "  └── 📄 image_06721.jpg\n",
      "  └── 📄 image_06704.jpg\n",
      "  └── 📄 image_06697.jpg\n",
      "\n",
      "📁 ./data/flowers/train/class_091\n",
      "  └── 📄 image_04858.jpg\n",
      "  └── 📄 image_04891.jpg\n",
      "  └── 📄 image_04868.jpg\n",
      "  └── 📄 image_04846.jpg\n",
      "  └── 📄 image_04862.jpg\n",
      "\n",
      "📁 ./data/flowers/train/class_011\n",
      "  └── 📄 image_03161.jpg\n",
      "  └── 📄 image_03096.jpg\n",
      "  └── 📄 image_03151.jpg\n",
      "  └── 📄 image_03128.jpg\n",
      "  └── 📄 image_03123.jpg\n",
      "\n",
      "📁 ./data/flowers/train/class_099\n",
      "  └── 📄 image_07848.jpg\n",
      "  └── 📄 image_07874.jpg\n",
      "  └── 📄 image_07880.jpg\n",
      "  └── 📄 image_08063.jpg\n",
      "  └── 📄 image_07864.jpg\n",
      "\n",
      "📁 ./data/flowers/train/class_022\n",
      "  └── 📄 image_05373.jpg\n",
      "  └── 📄 image_05353.jpg\n",
      "  └── 📄 image_05376.jpg\n",
      "  └── 📄 image_05354.jpg\n",
      "  └── 📄 image_05347.jpg\n",
      "\n",
      "📁 ./data/flowers/train/class_003\n",
      "  └── 📄 image_06650.jpg\n",
      "  └── 📄 image_06635.jpg\n",
      "  └── 📄 image_06641.jpg\n",
      "  └── 📄 image_06645.jpg\n",
      "  └── 📄 image_06630.jpg\n",
      "\n",
      "📁 ./data/flowers/train/class_008\n",
      "  └── 📄 image_03319.jpg\n",
      "  └── 📄 image_03321.jpg\n",
      "  └── 📄 image_03366.jpg\n",
      "  └── 📄 image_03353.jpg\n",
      "  └── 📄 image_03311.jpg\n",
      "\n",
      "📁 ./data/flowers/train/class_045\n",
      "  └── 📄 image_07142.jpg\n",
      "  └── 📄 image_07152.jpg\n",
      "  └── 📄 image_07129.jpg\n",
      "  └── 📄 image_07148.jpg\n",
      "  └── 📄 image_07137.jpg\n",
      "\n",
      "📁 ./data/flowers/train/class_051\n",
      "  └── 📄 image_03973.jpg\n",
      "  └── 📄 image_01325.jpg\n",
      "  └── 📄 image_01477.jpg\n",
      "  └── 📄 image_03953.jpg\n",
      "  └── 📄 image_01436.jpg\n",
      "\n",
      "📁 ./data/flowers/train/class_021\n",
      "  └── 📄 image_06778.jpg\n",
      "  └── 📄 image_06792.jpg\n",
      "  └── 📄 image_06805.jpg\n",
      "  └── 📄 image_06809.jpg\n",
      "  └── 📄 image_06780.jpg\n",
      "\n",
      "📁 ./data/flowers/train/class_090\n",
      "  └── 📄 image_04410.jpg\n",
      "  └── 📄 image_04444.jpg\n",
      "  └── 📄 image_04430.jpg\n",
      "  └── 📄 image_04461.jpg\n",
      "  └── 📄 image_04445.jpg\n",
      "\n",
      "📁 ./data/flowers/train/class_089\n",
      "  └── 📄 image_00638.jpg\n",
      "  └── 📄 image_00694.jpg\n",
      "  └── 📄 image_00631.jpg\n",
      "  └── 📄 image_00637.jpg\n",
      "  └── 📄 image_00627.jpg\n",
      "\n",
      "📁 ./data/flowers/train/class_016\n",
      "  └── 📄 image_06669.jpg\n",
      "  └── 📄 image_06687.jpg\n",
      "  └── 📄 image_06667.jpg\n",
      "  └── 📄 image_06674.jpg\n",
      "  └── 📄 image_06691.jpg\n",
      "\n",
      "📁 ./data/flowers/train/class_087\n",
      "  └── 📄 image_05477.jpg\n",
      "  └── 📄 image_05517.jpg\n",
      "  └── 📄 image_05473.jpg\n",
      "  └── 📄 image_05518.jpg\n",
      "  └── 📄 image_05467.jpg\n",
      "\n",
      "📁 ./data/flowers/train/class_058\n",
      "  └── 📄 image_02714.jpg\n",
      "  └── 📄 image_02671.jpg\n",
      "  └── 📄 image_02735.jpg\n",
      "  └── 📄 image_02652.jpg\n",
      "  └── 📄 image_02701.jpg\n",
      "\n",
      "📁 ./data/flowers/train/class_040\n",
      "  └── 📄 image_04592.jpg\n",
      "  └── 📄 image_04620.jpg\n",
      "  └── 📄 image_04616.jpg\n",
      "  └── 📄 image_04608.jpg\n",
      "  └── 📄 image_04621.jpg\n",
      "\n",
      "📁 ./data/flowers/train/class_034\n",
      "  └── 📄 image_06968.jpg\n",
      "  └── 📄 image_06951.jpg\n",
      "  └── 📄 image_06943.jpg\n",
      "  └── 📄 image_06956.jpg\n",
      "  └── 📄 image_06937.jpg\n",
      "\n",
      "📁 ./data/flowers/train/class_053\n",
      "  └── 📄 image_03728.jpg\n",
      "  └── 📄 image_03707.jpg\n",
      "  └── 📄 image_03716.jpg\n",
      "  └── 📄 image_03704.jpg\n",
      "  └── 📄 image_03666.jpg\n",
      "\n",
      "📁 ./data/flowers/train/class_025\n",
      "  └── 📄 image_06592.jpg\n",
      "  └── 📄 image_06583.jpg\n",
      "  └── 📄 image_06588.jpg\n",
      "  └── 📄 image_06605.jpg\n",
      "  └── 📄 image_06589.jpg\n",
      "\n",
      "📁 ./data/flowers/train/class_028\n",
      "  └── 📄 image_05276.jpg\n",
      "  └── 📄 image_05255.jpg\n",
      "  └── 📄 image_05268.jpg\n",
      "  └── 📄 image_05259.jpg\n",
      "  └── 📄 image_05246.jpg\n",
      "\n",
      "📁 ./data/flowers/train/class_043\n",
      "  └── 📄 image_02420.jpg\n",
      "  └── 📄 image_02362.jpg\n",
      "  └── 📄 image_02334.jpg\n",
      "  └── 📄 image_02379.jpg\n",
      "  └── 📄 image_02439.jpg\n",
      "\n",
      "📁 ./data/flowers/train/class_010\n",
      "  └── 📄 image_07122.jpg\n",
      "  └── 📄 image_08096.jpg\n",
      "  └── 📄 image_08090.jpg\n",
      "  └── 📄 image_07091.jpg\n",
      "  └── 📄 image_07114.jpg\n",
      "\n",
      "📁 ./data/flowers/train/class_018\n",
      "  └── 📄 image_04248.jpg\n",
      "  └── 📄 image_04265.jpg\n",
      "  └── 📄 image_04299.jpg\n",
      "  └── 📄 image_04271.jpg\n",
      "  └── 📄 image_04250.jpg\n",
      "\n",
      "📁 ./data/flowers/train/class_100\n",
      "  └── 📄 image_07917.jpg\n",
      "  └── 📄 image_07933.jpg\n",
      "  └── 📄 image_07904.jpg\n",
      "  └── 📄 image_07911.jpg\n",
      "  └── 📄 image_07897.jpg\n",
      "\n",
      "📁 ./data/flowers/train/class_026\n",
      "  └── 📄 image_06523.jpg\n",
      "  └── 📄 image_06527.jpg\n",
      "  └── 📄 image_06489.jpg\n",
      "  └── 📄 image_06502.jpg\n",
      "  └── 📄 image_06515.jpg\n",
      "\n",
      "📁 ./data/flowers/train/class_074\n",
      "  └── 📄 image_01233.jpg\n",
      "  └── 📄 image_01272.jpg\n",
      "  └── 📄 image_01284.jpg\n",
      "  └── 📄 image_01269.jpg\n",
      "  └── 📄 image_01171.jpg\n",
      "\n",
      "📁 ./data/flowers/train/class_023\n",
      "  └── 📄 image_03392.jpg\n",
      "  └── 📄 image_03422.jpg\n",
      "  └── 📄 image_03444.jpg\n",
      "  └── 📄 image_03417.jpg\n",
      "  └── 📄 image_03432.jpg\n",
      "\n",
      "📁 ./data/flowers/train/class_085\n",
      "  └── 📄 image_04794.jpg\n",
      "  └── 📄 image_04775.jpg\n",
      "  └── 📄 image_04816.jpg\n",
      "  └── 📄 image_04819.jpg\n",
      "  └── 📄 image_04799.jpg\n",
      "\n",
      "📁 ./data/flowers/train/class_081\n",
      "  └── 📄 image_00783.jpg\n",
      "  └── 📄 image_00916.jpg\n",
      "  └── 📄 image_00840.jpg\n",
      "  └── 📄 image_00829.jpg\n",
      "  └── 📄 image_00810.jpg\n",
      "\n",
      "📁 ./data/flowers/train/class_019\n",
      "  └── 📄 image_06160.jpg\n",
      "  └── 📄 image_06174.jpg\n",
      "  └── 📄 image_06166.jpg\n",
      "  └── 📄 image_06171.jpg\n",
      "  └── 📄 image_06182.jpg\n",
      "\n",
      "📁 ./data/flowers/train/class_052\n",
      "  └── 📄 image_04203.jpg\n",
      "  └── 📄 image_04185.jpg\n",
      "  └── 📄 image_04201.jpg\n",
      "  └── 📄 image_04228.jpg\n",
      "  └── 📄 image_04230.jpg\n",
      "\n",
      "📁 ./data/flowers/train/class_035\n",
      "  └── 📄 image_06984.jpg\n",
      "  └── 📄 image_06983.jpg\n",
      "  └── 📄 image_06975.jpg\n",
      "  └── 📄 image_06977.jpg\n",
      "  └── 📄 image_07000.jpg\n",
      "\n",
      "📁 ./data/flowers/train/class_094\n",
      "  └── 📄 image_07411.jpg\n",
      "  └── 📄 image_07443.jpg\n",
      "  └── 📄 image_07433.jpg\n",
      "  └── 📄 image_07396.jpg\n",
      "  └── 📄 image_07305.jpg\n",
      "\n",
      "📁 ./data/flowers/train/class_092\n",
      "  └── 📄 image_03087.jpg\n",
      "  └── 📄 image_03086.jpg\n",
      "  └── 📄 image_03091.jpg\n",
      "  └── 📄 image_03065.jpg\n",
      "  └── 📄 image_03033.jpg\n",
      "\n",
      "📁 ./data/flowers/train/class_076\n",
      "  └── 📄 image_02519.jpg\n",
      "  └── 📄 image_02518.jpg\n",
      "  └── 📄 image_02477.jpg\n",
      "  └── 📄 image_02513.jpg\n",
      "  └── 📄 image_02526.jpg\n",
      "\n",
      "📁 ./data/flowers/train/class_075\n",
      "  └── 📄 image_02090.jpg\n",
      "  └── 📄 image_02074.jpg\n",
      "  └── 📄 image_02137.jpg\n",
      "  └── 📄 image_02154.jpg\n",
      "  └── 📄 image_02141.jpg\n",
      "\n",
      "📁 ./data/flowers/train/class_055\n",
      "  └── 📄 image_04746.jpg\n",
      "  └── 📄 image_04740.jpg\n",
      "  └── 📄 image_04718.jpg\n",
      "  └── 📄 image_04762.jpg\n",
      "  └── 📄 image_04700.jpg\n",
      "\n",
      "📁 ./data/flowers/train/class_098\n",
      "  └── 📄 image_07831.jpg\n",
      "  └── 📄 image_07828.jpg\n",
      "  └── 📄 image_07753.jpg\n",
      "  └── 📄 image_07823.jpg\n",
      "  └── 📄 image_07800.jpg\n",
      "\n",
      "📁 ./data/flowers/train/class_072\n",
      "  └── 📄 image_03554.jpg\n",
      "  └── 📄 image_03568.jpg\n",
      "  └── 📄 image_03548.jpg\n",
      "  └── 📄 image_03608.jpg\n",
      "  └── 📄 image_03631.jpg\n",
      "\n",
      "📁 ./data/flowers/train/class_060\n",
      "  └── 📄 image_03026.jpg\n",
      "  └── 📄 image_02926.jpg\n",
      "  └── 📄 image_03004.jpg\n",
      "  └── 📄 image_03027.jpg\n",
      "  └── 📄 image_02949.jpg\n",
      "\n",
      "📁 ./data/flowers/train/class_084\n",
      "  └── 📄 image_02630.jpg\n",
      "  └── 📄 image_02616.jpg\n",
      "  └── 📄 image_02624.jpg\n",
      "  └── 📄 image_02612.jpg\n",
      "  └── 📄 image_02579.jpg\n",
      "\n",
      "📁 ./data/flowers/train/class_064\n",
      "  └── 📄 image_06145.jpg\n",
      "  └── 📄 image_06127.jpg\n",
      "  └── 📄 image_06110.jpg\n",
      "  └── 📄 image_06139.jpg\n",
      "  └── 📄 image_06106.jpg\n",
      "\n",
      "📁 ./data/flowers/train/class_096\n",
      "  └── 📄 image_07683.jpg\n",
      "  └── 📄 image_07644.jpg\n",
      "  └── 📄 image_07608.jpg\n",
      "  └── 📄 image_07630.jpg\n",
      "  └── 📄 image_07613.jpg\n",
      "\n",
      "📁 ./data/flowers/train/class_069\n",
      "  └── 📄 image_05977.jpg\n",
      "  └── 📄 image_05990.jpg\n",
      "  └── 📄 image_05995.jpg\n",
      "  └── 📄 image_05985.jpg\n",
      "  └── 📄 image_05997.jpg\n",
      "\n",
      "📁 ./data/flowers/train/class_050\n",
      "  └── 📄 image_06554.jpg\n",
      "  └── 📄 image_06538.jpg\n",
      "  └── 📄 image_06540.jpg\n",
      "  └── 📄 image_06564.jpg\n",
      "  └── 📄 image_06320.jpg\n",
      "\n",
      "📁 ./data/flowers/train/class_065\n",
      "  └── 📄 image_03242.jpg\n",
      "  └── 📄 image_03184.jpg\n",
      "  └── 📄 image_03235.jpg\n",
      "  └── 📄 image_03215.jpg\n",
      "  └── 📄 image_03255.jpg\n",
      "\n",
      "📁 ./data/flowers/train/class_017\n",
      "  └── 📄 image_03864.jpg\n",
      "  └── 📄 image_03883.jpg\n",
      "  └── 📄 image_03846.jpg\n",
      "  └── 📄 image_03830.jpg\n",
      "  └── 📄 image_03838.jpg\n",
      "\n",
      "📁 ./data/flowers/train/class_005\n",
      "  └── 📄 image_05157.jpg\n",
      "  └── 📄 image_05186.jpg\n",
      "  └── 📄 image_05199.jpg\n",
      "  └── 📄 image_05181.jpg\n",
      "  └── 📄 image_05179.jpg\n",
      "\n",
      "📁 ./data/flowers/train/class_033\n",
      "  └── 📄 image_06465.jpg\n",
      "  └── 📄 image_06441.jpg\n",
      "  └── 📄 image_06478.jpg\n",
      "  └── 📄 image_06468.jpg\n",
      "  └── 📄 image_06450.jpg\n",
      "\n",
      "📁 ./data/flowers/train/class_059\n",
      "  └── 📄 image_05029.jpg\n",
      "  └── 📄 image_05036.jpg\n",
      "  └── 📄 image_05025.jpg\n",
      "  └── 📄 image_05080.jpg\n",
      "  └── 📄 image_05049.jpg\n",
      "\n",
      "📁 ./data/flowers/train/class_039\n",
      "  └── 📄 image_07008.jpg\n",
      "  └── 📄 image_07022.jpg\n",
      "  └── 📄 image_08081.jpg\n",
      "  └── 📄 image_07035.jpg\n",
      "  └── 📄 image_07016.jpg\n",
      "\n",
      "📁 ./data/flowers/train/class_041\n",
      "  └── 📄 image_02201.jpg\n",
      "  └── 📄 image_02193.jpg\n",
      "  └── 📄 image_02273.jpg\n",
      "  └── 📄 image_02194.jpg\n",
      "  └── 📄 image_02242.jpg\n",
      "\n",
      "📁 ./data/flowers/train/class_067\n",
      "  └── 📄 image_07049.jpg\n",
      "  └── 📄 image_07076.jpg\n",
      "  └── 📄 image_07059.jpg\n",
      "  └── 📄 image_07065.jpg\n",
      "  └── 📄 image_07064.jpg\n",
      "\n",
      "📁 ./data/flowers/train/class_036\n",
      "  └── 📄 image_04389.jpg\n",
      "  └── 📄 image_04340.jpg\n",
      "  └── 📄 image_04327.jpg\n",
      "  └── 📄 image_04387.jpg\n",
      "  └── 📄 image_04369.jpg\n",
      "\n",
      "📁 ./data/flowers/train/class_082\n",
      "  └── 📄 image_01635.jpg\n",
      "  └── 📄 image_01614.jpg\n",
      "  └── 📄 image_01649.jpg\n",
      "  └── 📄 image_01666.jpg\n",
      "  └── 📄 image_01611.jpg\n",
      "\n",
      "📁 ./data/flowers/train/class_015\n",
      "  └── 📄 image_06372.jpg\n",
      "  └── 📄 image_06349.jpg\n",
      "  └── 📄 image_06384.jpg\n",
      "  └── 📄 image_06370.jpg\n",
      "  └── 📄 image_06374.jpg\n",
      "\n",
      "📁 ./data/flowers/train/class_062\n",
      "  └── 📄 image_08178.jpg\n",
      "  └── 📄 image_07270.jpg\n",
      "  └── 📄 image_08159.jpg\n",
      "  └── 📄 image_08164.jpg\n",
      "  └── 📄 image_08170.jpg\n",
      "\n",
      "📁 ./data/flowers/train/class_097\n",
      "  └── 📄 image_07693.jpg\n",
      "  └── 📄 image_07742.jpg\n",
      "  └── 📄 image_07728.jpg\n",
      "  └── 📄 image_07687.jpg\n",
      "  └── 📄 image_07743.jpg\n",
      "\n",
      "📁 ./data/flowers/train/class_009\n",
      "  └── 📄 image_06416.jpg\n",
      "  └── 📄 image_06408.jpg\n",
      "  └── 📄 image_06405.jpg\n",
      "  └── 📄 image_06411.jpg\n",
      "  └── 📄 image_06427.jpg\n",
      "\n",
      "📁 ./data/flowers/train/class_037\n",
      "  └── 📄 image_03752.jpg\n",
      "  └── 📄 image_03808.jpg\n",
      "  └── 📄 image_07295.jpg\n",
      "  └── 📄 image_03783.jpg\n",
      "  └── 📄 image_03813.jpg\n",
      "\n",
      "📁 ./data/flowers/train/class_006\n",
      "  └── 📄 image_07198.jpg\n",
      "  └── 📄 image_08108.jpg\n",
      "  └── 📄 image_08109.jpg\n",
      "  └── 📄 image_07168.jpg\n",
      "  └── 📄 image_07184.jpg\n",
      "\n",
      "📁 ./data/flowers/train/class_057\n",
      "  └── 📄 image_07244.jpg\n",
      "  └── 📄 image_07254.jpg\n",
      "  └── 📄 image_08145.jpg\n",
      "  └── 📄 image_08142.jpg\n",
      "  └── 📄 image_08126.jpg\n",
      "\n",
      "📁 ./data/flowers/train/class_002\n",
      "  └── 📄 image_05146.jpg\n",
      "  └── 📄 image_05132.jpg\n",
      "  └── 📄 image_05114.jpg\n",
      "  └── 📄 image_05112.jpg\n",
      "  └── 📄 image_05091.jpg\n",
      "\n",
      "📁 ./data/flowers/train/class_014\n",
      "  └── 📄 image_06087.jpg\n",
      "  └── 📄 image_06067.jpg\n",
      "  └── 📄 image_06062.jpg\n",
      "  └── 📄 image_06060.jpg\n",
      "  └── 📄 image_06089.jpg\n",
      "\n",
      "📁 ./data/flowers/train/class_042\n",
      "  └── 📄 image_05697.jpg\n",
      "  └── 📄 image_05724.jpg\n",
      "  └── 📄 image_05692.jpg\n",
      "  └── 📄 image_05734.jpg\n",
      "  └── 📄 image_05706.jpg\n",
      "\n",
      "📁 ./data/flowers/train/class_095\n",
      "  └── 📄 image_07470.jpg\n",
      "  └── 📄 image_07506.jpg\n",
      "  └── 📄 image_07544.jpg\n",
      "  └── 📄 image_07566.jpg\n",
      "  └── 📄 image_07499.jpg\n",
      "\n",
      "📁 ./data/flowers/train/class_038\n",
      "  └── 📄 image_05809.jpg\n",
      "  └── 📄 image_05824.jpg\n",
      "  └── 📄 image_05821.jpg\n",
      "  └── 📄 image_05839.jpg\n",
      "  └── 📄 image_05837.jpg\n",
      "\n",
      "📁 ./data/flowers/train/class_077\n",
      "  └── 📄 image_00087.jpg\n",
      "  └── 📄 image_00155.jpg\n",
      "  └── 📄 image_00154.jpg\n",
      "  └── 📄 image_00016.jpg\n",
      "  └── 📄 image_00201.jpg\n",
      "\n",
      "📁 ./data/flowers/train/class_004\n",
      "  └── 📄 image_05674.jpg\n",
      "  └── 📄 image_05650.jpg\n",
      "  └── 📄 image_05632.jpg\n",
      "  └── 📄 image_05659.jpg\n",
      "  └── 📄 image_05658.jpg\n",
      "\n",
      "📁 ./data/flowers/train/class_048\n",
      "  └── 📄 image_04641.jpg\n",
      "  └── 📄 image_04653.jpg\n",
      "  └── 📄 image_04682.jpg\n",
      "  └── 📄 image_04644.jpg\n",
      "  └── 📄 image_04666.jpg\n",
      "\n",
      "📁 ./data/flowers/train/class_020\n",
      "  └── 📄 image_04929.jpg\n",
      "  └── 📄 image_04935.jpg\n",
      "  └── 📄 image_04919.jpg\n",
      "  └── 📄 image_04908.jpg\n",
      "  └── 📄 image_04900.jpg\n",
      "\n",
      "📁 ./data/flowers/train/class_061\n",
      "  └── 📄 image_06265.jpg\n",
      "  └── 📄 image_06248.jpg\n",
      "  └── 📄 image_06283.jpg\n",
      "  └── 📄 image_06264.jpg\n",
      "  └── 📄 image_06261.jpg\n",
      "\n",
      "📁 ./data/flowers/train/class_073\n",
      "  └── 📄 image_00366.jpg\n",
      "  └── 📄 image_00431.jpg\n",
      "  └── 📄 image_00416.jpg\n",
      "  └── 📄 image_00266.jpg\n",
      "  └── 📄 image_00345.jpg\n",
      "\n",
      "📁 ./data/flowers/test\n",
      "  └── 📂 class_029\n",
      "  └── 📂 class_027\n",
      "  └── 📂 class_013\n",
      "  └── 📂 class_001\n",
      "  └── 📂 class_024\n",
      "  └── 📂 class_102\n",
      "  └── 📂 class_032\n",
      "  └── 📂 class_078\n",
      "  └── 📂 class_054\n",
      "  └── 📂 class_093\n",
      "  └── 📂 class_047\n",
      "  └── 📂 class_007\n",
      "  └── 📂 class_071\n",
      "  └── 📂 class_030\n",
      "  └── 📂 class_044\n",
      "  └── 📂 class_086\n",
      "  └── 📂 class_083\n",
      "  └── 📂 class_080\n",
      "  └── 📂 class_070\n",
      "  └── 📂 class_046\n",
      "  └── 📂 class_049\n",
      "  └── 📂 class_088\n",
      "  └── 📂 class_063\n",
      "  └── 📂 class_012\n",
      "  └── 📂 class_066\n",
      "  └── 📂 class_031\n",
      "  └── 📂 class_056\n",
      "  └── 📂 class_068\n",
      "  └── 📂 class_101\n",
      "  └── 📂 class_079\n",
      "  └── 📂 class_091\n",
      "  └── 📂 class_011\n",
      "  └── 📂 class_099\n",
      "  └── 📂 class_022\n",
      "  └── 📂 class_003\n",
      "  └── 📂 class_008\n",
      "  └── 📂 class_045\n",
      "  └── 📂 class_051\n",
      "  └── 📂 class_021\n",
      "  └── 📂 class_090\n",
      "  └── 📂 class_089\n",
      "  └── 📂 class_016\n",
      "  └── 📂 class_087\n",
      "  └── 📂 class_058\n",
      "  └── 📂 class_040\n",
      "  └── 📂 class_034\n",
      "  └── 📂 class_053\n",
      "  └── 📂 class_025\n",
      "  └── 📂 class_028\n",
      "  └── 📂 class_043\n",
      "  └── 📂 class_010\n",
      "  └── 📂 class_018\n",
      "  └── 📂 class_100\n",
      "  └── 📂 class_026\n",
      "  └── 📂 class_074\n",
      "  └── 📂 class_023\n",
      "  └── 📂 class_085\n",
      "  └── 📂 class_081\n",
      "  └── 📂 class_019\n",
      "  └── 📂 class_052\n",
      "  └── 📂 class_035\n",
      "  └── 📂 class_094\n",
      "  └── 📂 class_092\n",
      "  └── 📂 class_076\n",
      "  └── 📂 class_075\n",
      "  └── 📂 class_055\n",
      "  └── 📂 class_098\n",
      "  └── 📂 class_072\n",
      "  └── 📂 class_060\n",
      "  └── 📂 class_084\n",
      "  └── 📂 class_064\n",
      "  └── 📂 class_096\n",
      "  └── 📂 class_069\n",
      "  └── 📂 class_050\n",
      "  └── 📂 class_065\n",
      "  └── 📂 class_017\n",
      "  └── 📂 class_005\n",
      "  └── 📂 class_033\n",
      "  └── 📂 class_059\n",
      "  └── 📂 class_039\n",
      "  └── 📂 class_041\n",
      "  └── 📂 class_067\n",
      "  └── 📂 class_036\n",
      "  └── 📂 class_082\n",
      "  └── 📂 class_015\n",
      "  └── 📂 class_062\n",
      "  └── 📂 class_097\n",
      "  └── 📂 class_009\n",
      "  └── 📂 class_037\n",
      "  └── 📂 class_006\n",
      "  └── 📂 class_057\n",
      "  └── 📂 class_002\n",
      "  └── 📂 class_014\n",
      "  └── 📂 class_042\n",
      "  └── 📂 class_095\n",
      "  └── 📂 class_038\n",
      "  └── 📂 class_077\n",
      "  └── 📂 class_004\n",
      "  └── 📂 class_048\n",
      "  └── 📂 class_020\n",
      "  └── 📂 class_061\n",
      "  └── 📂 class_073\n",
      "\n",
      "📁 ./data/flowers/test/class_029\n",
      "  └── 📄 image_04106.jpg\n",
      "  └── 📄 image_04094.jpg\n",
      "  └── 📄 image_04087.jpg\n",
      "  └── 📄 image_04128.jpg\n",
      "  └── 📄 image_04131.jpg\n",
      "\n",
      "📁 ./data/flowers/test/class_027\n",
      "  └── 📄 image_06886.jpg\n",
      "  └── 📄 image_06866.jpg\n",
      "  └── 📄 image_06880.jpg\n",
      "  └── 📄 image_06862.jpg\n",
      "  └── 📄 image_06888.jpg\n",
      "\n",
      "📁 ./data/flowers/test/class_013\n",
      "  └── 📄 image_05780.jpg\n",
      "  └── 📄 image_05772.jpg\n",
      "  └── 📄 image_05788.jpg\n",
      "  └── 📄 image_05748.jpg\n",
      "  └── 📄 image_05762.jpg\n",
      "\n",
      "📁 ./data/flowers/test/class_001\n",
      "  └── 📄 image_06739.jpg\n",
      "  └── 📄 image_06766.jpg\n",
      "  └── 📄 image_06755.jpg\n",
      "  └── 📄 image_06757.jpg\n",
      "  └── 📄 image_06736.jpg\n",
      "\n",
      "📁 ./data/flowers/test/class_024\n",
      "  └── 📄 image_06833.jpg\n",
      "  └── 📄 image_06840.jpg\n",
      "  └── 📄 image_06837.jpg\n",
      "  └── 📄 image_08050.jpg\n",
      "  └── 📄 image_06822.jpg\n",
      "\n",
      "📁 ./data/flowers/test/class_102\n",
      "  └── 📄 image_08032.jpg\n",
      "  └── 📄 image_08029.jpg\n",
      "  └── 📄 image_08004.jpg\n",
      "  └── 📄 image_08033.jpg\n",
      "  └── 📄 image_08008.jpg\n",
      "\n",
      "📁 ./data/flowers/test/class_032\n",
      "  └── 📄 image_05611.jpg\n",
      "  └── 📄 image_05618.jpg\n",
      "  └── 📄 image_05601.jpg\n",
      "  └── 📄 image_05593.jpg\n",
      "  └── 📄 image_05584.jpg\n",
      "\n",
      "📁 ./data/flowers/test/class_078\n",
      "  └── 📄 image_01895.jpg\n",
      "  └── 📄 image_01935.jpg\n",
      "  └── 📄 image_01940.jpg\n",
      "  └── 📄 image_01840.jpg\n",
      "  └── 📄 image_01854.jpg\n",
      "\n",
      "📁 ./data/flowers/test/class_054\n",
      "  └── 📄 image_05455.jpg\n",
      "  └── 📄 image_05417.jpg\n",
      "  └── 📄 image_05425.jpg\n",
      "  └── 📄 image_05434.jpg\n",
      "  └── 📄 image_05414.jpg\n",
      "\n",
      "📁 ./data/flowers/test/class_093\n",
      "  └── 📄 image_06036.jpg\n",
      "  └── 📄 image_08114.jpg\n",
      "  └── 📄 image_06039.jpg\n",
      "  └── 📄 image_06026.jpg\n",
      "  └── 📄 image_06048.jpg\n",
      "\n",
      "📁 ./data/flowers/test/class_047\n",
      "  └── 📄 image_04993.jpg\n",
      "  └── 📄 image_04991.jpg\n",
      "  └── 📄 image_05011.jpg\n",
      "  └── 📄 image_05017.jpg\n",
      "  └── 📄 image_05015.jpg\n",
      "\n",
      "📁 ./data/flowers/test/class_007\n",
      "  └── 📄 image_07223.jpg\n",
      "  └── 📄 image_07211.jpg\n",
      "  └── 📄 image_07200.jpg\n",
      "  └── 📄 image_07227.jpg\n",
      "  └── 📄 image_07208.jpg\n",
      "\n",
      "📁 ./data/flowers/test/class_071\n",
      "  └── 📄 image_04510.jpg\n",
      "  └── 📄 image_04520.jpg\n",
      "  └── 📄 image_04539.jpg\n",
      "  └── 📄 image_04537.jpg\n",
      "  └── 📄 image_04556.jpg\n",
      "\n",
      "📁 ./data/flowers/test/class_030\n",
      "  └── 📄 image_03463.jpg\n",
      "  └── 📄 image_03516.jpg\n",
      "  └── 📄 image_03518.jpg\n",
      "  └── 📄 image_03535.jpg\n",
      "  └── 📄 image_03492.jpg\n",
      "\n",
      "📁 ./data/flowers/test/class_044\n",
      "  └── 📄 image_01521.jpg\n",
      "  └── 📄 image_01515.jpg\n",
      "  └── 📄 image_01505.jpg\n",
      "  └── 📄 image_01530.jpg\n",
      "  └── 📄 image_01526.jpg\n",
      "\n",
      "📁 ./data/flowers/test/class_086\n",
      "  └── 📄 image_02867.jpg\n",
      "  └── 📄 image_02870.jpg\n",
      "  └── 📄 image_02873.jpg\n",
      "  └── 📄 image_02891.jpg\n",
      "  └── 📄 image_02888.jpg\n",
      "\n",
      "📁 ./data/flowers/test/class_083\n",
      "  └── 📄 image_01781.jpg\n",
      "  └── 📄 image_01772.jpg\n",
      "  └── 📄 image_01777.jpg\n",
      "  └── 📄 image_01763.jpg\n",
      "  └── 📄 image_01722.jpg\n",
      "\n",
      "📁 ./data/flowers/test/class_080\n",
      "  └── 📄 image_02047.jpg\n",
      "  └── 📄 image_02045.jpg\n",
      "  └── 📄 image_01983.jpg\n",
      "  └── 📄 image_01999.jpg\n",
      "  └── 📄 image_01994.jpg\n",
      "\n",
      "📁 ./data/flowers/test/class_070\n",
      "  └── 📄 image_05292.jpg\n",
      "  └── 📄 image_05289.jpg\n",
      "  └── 📄 image_05321.jpg\n",
      "  └── 📄 image_05318.jpg\n",
      "  └── 📄 image_05314.jpg\n",
      "\n",
      "📁 ./data/flowers/test/class_046\n",
      "  └── 📄 image_00990.jpg\n",
      "  └── 📄 image_01141.jpg\n",
      "  └── 📄 image_01095.jpg\n",
      "  └── 📄 image_00979.jpg\n",
      "  └── 📄 image_01129.jpg\n",
      "\n",
      "📁 ./data/flowers/test/class_049\n",
      "  └── 📄 image_06224.jpg\n",
      "  └── 📄 image_06217.jpg\n",
      "  └── 📄 image_06236.jpg\n",
      "  └── 📄 image_06206.jpg\n",
      "  └── 📄 image_06242.jpg\n",
      "\n",
      "📁 ./data/flowers/test/class_088\n",
      "  └── 📄 image_00452.jpg\n",
      "  └── 📄 image_00505.jpg\n",
      "  └── 📄 image_00493.jpg\n",
      "  └── 📄 image_00448.jpg\n",
      "  └── 📄 image_00481.jpg\n",
      "\n",
      "📁 ./data/flowers/test/class_063\n",
      "  └── 📄 image_05849.jpg\n",
      "  └── 📄 image_05900.jpg\n",
      "  └── 📄 image_05857.jpg\n",
      "  └── 📄 image_05873.jpg\n",
      "  └── 📄 image_05851.jpg\n",
      "\n",
      "📁 ./data/flowers/test/class_012\n",
      "  └── 📄 image_04026.jpg\n",
      "  └── 📄 image_04003.jpg\n",
      "  └── 📄 image_04050.jpg\n",
      "  └── 📄 image_04059.jpg\n",
      "  └── 📄 image_04013.jpg\n",
      "\n",
      "📁 ./data/flowers/test/class_066\n",
      "  └── 📄 image_05580.jpg\n",
      "  └── 📄 image_05525.jpg\n",
      "  └── 📄 image_05546.jpg\n",
      "  └── 📄 image_05537.jpg\n",
      "  └── 📄 image_05542.jpg\n",
      "\n",
      "📁 ./data/flowers/test/class_031\n",
      "  └── 📄 image_06898.jpg\n",
      "  └── 📄 image_06910.jpg\n",
      "  └── 📄 image_06911.jpg\n",
      "  └── 📄 image_06893.jpg\n",
      "  └── 📄 image_06900.jpg\n",
      "\n",
      "📁 ./data/flowers/test/class_056\n",
      "  └── 📄 image_02812.jpg\n",
      "  └── 📄 image_02851.jpg\n",
      "  └── 📄 image_02819.jpg\n",
      "  └── 📄 image_02779.jpg\n",
      "  └── 📄 image_02775.jpg\n",
      "\n",
      "📁 ./data/flowers/test/class_068\n",
      "  └── 📄 image_05912.jpg\n",
      "  └── 📄 image_05946.jpg\n",
      "  └── 📄 image_05905.jpg\n",
      "  └── 📄 image_05956.jpg\n",
      "  └── 📄 image_05940.jpg\n",
      "\n",
      "📁 ./data/flowers/test/class_101\n",
      "  └── 📄 image_07958.jpg\n",
      "  └── 📄 image_07991.jpg\n",
      "  └── 📄 image_07952.jpg\n",
      "  └── 📄 image_07955.jpg\n",
      "  └── 📄 image_07959.jpg\n",
      "\n",
      "📁 ./data/flowers/test/class_079\n",
      "  └── 📄 image_06714.jpg\n",
      "  └── 📄 image_06725.jpg\n",
      "  └── 📄 image_06717.jpg\n",
      "  └── 📄 image_06712.jpg\n",
      "  └── 📄 image_06708.jpg\n",
      "\n",
      "📁 ./data/flowers/test/class_091\n",
      "  └── 📄 image_04874.jpg\n",
      "  └── 📄 image_04854.jpg\n",
      "  └── 📄 image_04857.jpg\n",
      "  └── 📄 image_08055.jpg\n",
      "  └── 📄 image_04833.jpg\n",
      "\n",
      "📁 ./data/flowers/test/class_011\n",
      "  └── 📄 image_03131.jpg\n",
      "  └── 📄 image_03138.jpg\n",
      "  └── 📄 image_03147.jpg\n",
      "  └── 📄 image_03166.jpg\n",
      "  └── 📄 image_03135.jpg\n",
      "\n",
      "📁 ./data/flowers/test/class_099\n",
      "  └── 📄 image_07851.jpg\n",
      "  └── 📄 image_07840.jpg\n",
      "  └── 📄 image_07856.jpg\n",
      "  └── 📄 image_07837.jpg\n",
      "  └── 📄 image_07853.jpg\n",
      "\n",
      "📁 ./data/flowers/test/class_022\n",
      "  └── 📄 image_05377.jpg\n",
      "  └── 📄 image_05375.jpg\n",
      "  └── 📄 image_05341.jpg\n",
      "  └── 📄 image_05385.jpg\n",
      "  └── 📄 image_05357.jpg\n",
      "\n",
      "📁 ./data/flowers/test/class_003\n",
      "  └── 📄 image_06618.jpg\n",
      "  └── 📄 image_06624.jpg\n",
      "  └── 📄 image_06621.jpg\n",
      "  └── 📄 image_06636.jpg\n",
      "  └── 📄 image_06639.jpg\n",
      "\n",
      "📁 ./data/flowers/test/class_008\n",
      "  └── 📄 image_03294.jpg\n",
      "  └── 📄 image_03296.jpg\n",
      "  └── 📄 image_03324.jpg\n",
      "  └── 📄 image_03286.jpg\n",
      "  └── 📄 image_03293.jpg\n",
      "\n",
      "📁 ./data/flowers/test/class_045\n",
      "  └── 📄 image_07144.jpg\n",
      "  └── 📄 image_07159.jpg\n",
      "  └── 📄 image_07156.jpg\n",
      "  └── 📄 image_07123.jpg\n",
      "  └── 📄 image_07154.jpg\n",
      "\n",
      "📁 ./data/flowers/test/class_051\n",
      "  └── 📄 image_01404.jpg\n",
      "  └── 📄 image_03956.jpg\n",
      "  └── 📄 image_01487.jpg\n",
      "  └── 📄 image_03948.jpg\n",
      "  └── 📄 image_01428.jpg\n",
      "\n",
      "📁 ./data/flowers/test/class_021\n",
      "  └── 📄 image_06796.jpg\n",
      "  └── 📄 image_06808.jpg\n",
      "  └── 📄 image_06795.jpg\n",
      "  └── 📄 image_06781.jpg\n",
      "  └── 📄 image_06786.jpg\n",
      "\n",
      "📁 ./data/flowers/test/class_090\n",
      "  └── 📄 image_04453.jpg\n",
      "  └── 📄 image_04421.jpg\n",
      "  └── 📄 image_04460.jpg\n",
      "  └── 📄 image_04424.jpg\n",
      "  └── 📄 image_04456.jpg\n",
      "\n",
      "📁 ./data/flowers/test/class_089\n",
      "  └── 📄 image_00601.jpg\n",
      "  └── 📄 image_00605.jpg\n",
      "  └── 📄 image_00753.jpg\n",
      "  └── 📄 image_00639.jpg\n",
      "  └── 📄 image_00691.jpg\n",
      "\n",
      "📁 ./data/flowers/test/class_016\n",
      "  └── 📄 image_06654.jpg\n",
      "  └── 📄 image_06680.jpg\n",
      "  └── 📄 image_06692.jpg\n",
      "  └── 📄 image_06659.jpg\n",
      "  └── 📄 image_06688.jpg\n",
      "\n",
      "📁 ./data/flowers/test/class_087\n",
      "  └── 📄 image_05472.jpg\n",
      "  └── 📄 image_05486.jpg\n",
      "  └── 📄 image_05503.jpg\n",
      "  └── 📄 image_05494.jpg\n",
      "  └── 📄 image_05466.jpg\n",
      "\n",
      "📁 ./data/flowers/test/class_058\n",
      "  └── 📄 image_02644.jpg\n",
      "  └── 📄 image_02717.jpg\n",
      "  └── 📄 image_02677.jpg\n",
      "  └── 📄 image_02685.jpg\n",
      "  └── 📄 image_02708.jpg\n",
      "\n",
      "📁 ./data/flowers/test/class_040\n",
      "  └── 📄 image_04609.jpg\n",
      "  └── 📄 image_04584.jpg\n",
      "  └── 📄 image_04606.jpg\n",
      "  └── 📄 image_04567.jpg\n",
      "  └── 📄 image_04624.jpg\n",
      "\n",
      "📁 ./data/flowers/test/class_034\n",
      "  └── 📄 image_06949.jpg\n",
      "  └── 📄 image_06962.jpg\n",
      "  └── 📄 image_06935.jpg\n",
      "  └── 📄 image_06933.jpg\n",
      "  └── 📄 image_06966.jpg\n",
      "\n",
      "📁 ./data/flowers/test/class_053\n",
      "  └── 📄 image_03647.jpg\n",
      "  └── 📄 image_03683.jpg\n",
      "  └── 📄 image_03721.jpg\n",
      "  └── 📄 image_03655.jpg\n",
      "  └── 📄 image_03709.jpg\n",
      "\n",
      "📁 ./data/flowers/test/class_025\n",
      "  └── 📄 image_06599.jpg\n",
      "  └── 📄 image_06596.jpg\n",
      "  └── 📄 image_06593.jpg\n",
      "  └── 📄 image_06581.jpg\n",
      "  └── 📄 image_06600.jpg\n",
      "\n",
      "📁 ./data/flowers/test/class_028\n",
      "  └── 📄 image_05235.jpg\n",
      "  └── 📄 image_05240.jpg\n",
      "  └── 📄 image_05263.jpg\n",
      "  └── 📄 image_05267.jpg\n",
      "  └── 📄 image_05212.jpg\n",
      "\n",
      "📁 ./data/flowers/test/class_043\n",
      "  └── 📄 image_02330.jpg\n",
      "  └── 📄 image_02368.jpg\n",
      "  └── 📄 image_02403.jpg\n",
      "  └── 📄 image_02445.jpg\n",
      "  └── 📄 image_02422.jpg\n",
      "\n",
      "📁 ./data/flowers/test/class_010\n",
      "  └── 📄 image_07093.jpg\n",
      "  └── 📄 image_07108.jpg\n",
      "  └── 📄 image_07110.jpg\n",
      "  └── 📄 image_07117.jpg\n",
      "  └── 📄 image_07116.jpg\n",
      "\n",
      "📁 ./data/flowers/test/class_018\n",
      "  └── 📄 image_04257.jpg\n",
      "  └── 📄 image_04280.jpg\n",
      "  └── 📄 image_04254.jpg\n",
      "  └── 📄 image_04272.jpg\n",
      "  └── 📄 image_04290.jpg\n",
      "\n",
      "📁 ./data/flowers/test/class_100\n",
      "  └── 📄 image_07903.jpg\n",
      "  └── 📄 image_07909.jpg\n",
      "  └── 📄 image_07920.jpg\n",
      "  └── 📄 image_07934.jpg\n",
      "  └── 📄 image_07893.jpg\n",
      "\n",
      "📁 ./data/flowers/test/class_026\n",
      "  └── 📄 image_06509.jpg\n",
      "  └── 📄 image_06488.jpg\n",
      "  └── 📄 image_06497.jpg\n",
      "  └── 📄 image_06522.jpg\n",
      "  └── 📄 image_06508.jpg\n",
      "\n",
      "📁 ./data/flowers/test/class_074\n",
      "  └── 📄 image_01189.jpg\n",
      "  └── 📄 image_01306.jpg\n",
      "  └── 📄 image_01274.jpg\n",
      "  └── 📄 image_01175.jpg\n",
      "  └── 📄 image_01146.jpg\n",
      "\n",
      "📁 ./data/flowers/test/class_023\n",
      "  └── 📄 image_03411.jpg\n",
      "  └── 📄 image_03421.jpg\n",
      "  └── 📄 image_03415.jpg\n",
      "  └── 📄 image_03447.jpg\n",
      "  └── 📄 image_03393.jpg\n",
      "\n",
      "📁 ./data/flowers/test/class_085\n",
      "  └── 📄 image_04826.jpg\n",
      "  └── 📄 image_04771.jpg\n",
      "  └── 📄 image_04767.jpg\n",
      "  └── 📄 image_04777.jpg\n",
      "  └── 📄 image_04817.jpg\n",
      "\n",
      "📁 ./data/flowers/test/class_081\n",
      "  └── 📄 image_00894.jpg\n",
      "  └── 📄 image_00785.jpg\n",
      "  └── 📄 image_00796.jpg\n",
      "  └── 📄 image_00907.jpg\n",
      "  └── 📄 image_00782.jpg\n",
      "\n",
      "📁 ./data/flowers/test/class_019\n",
      "  └── 📄 image_06154.jpg\n",
      "  └── 📄 image_06158.jpg\n",
      "  └── 📄 image_06188.jpg\n",
      "  └── 📄 image_06165.jpg\n",
      "  └── 📄 image_06159.jpg\n",
      "\n",
      "📁 ./data/flowers/test/class_052\n",
      "  └── 📄 image_04161.jpg\n",
      "  └── 📄 image_04160.jpg\n",
      "  └── 📄 image_04202.jpg\n",
      "  └── 📄 image_04223.jpg\n",
      "  └── 📄 image_04176.jpg\n",
      "\n",
      "📁 ./data/flowers/test/class_035\n",
      "  └── 📄 image_06994.jpg\n",
      "  └── 📄 image_06992.jpg\n",
      "  └── 📄 image_06974.jpg\n",
      "  └── 📄 image_06987.jpg\n",
      "  └── 📄 image_06972.jpg\n",
      "\n",
      "📁 ./data/flowers/test/class_094\n",
      "  └── 📄 image_07378.jpg\n",
      "  └── 📄 image_07435.jpg\n",
      "  └── 📄 image_07379.jpg\n",
      "  └── 📄 image_07366.jpg\n",
      "  └── 📄 image_07459.jpg\n",
      "\n",
      "📁 ./data/flowers/test/class_092\n",
      "  └── 📄 image_03090.jpg\n",
      "  └── 📄 image_03066.jpg\n",
      "  └── 📄 image_03068.jpg\n",
      "  └── 📄 image_03044.jpg\n",
      "  └── 📄 image_03070.jpg\n",
      "\n",
      "📁 ./data/flowers/test/class_076\n",
      "  └── 📄 image_02547.jpg\n",
      "  └── 📄 image_02478.jpg\n",
      "  └── 📄 image_02486.jpg\n",
      "  └── 📄 image_02464.jpg\n",
      "  └── 📄 image_02516.jpg\n",
      "\n",
      "📁 ./data/flowers/test/class_075\n",
      "  └── 📄 image_02108.jpg\n",
      "  └── 📄 image_02157.jpg\n",
      "  └── 📄 image_02156.jpg\n",
      "  └── 📄 image_02126.jpg\n",
      "  └── 📄 image_02075.jpg\n",
      "\n",
      "📁 ./data/flowers/test/class_055\n",
      "  └── 📄 image_04747.jpg\n",
      "  └── 📄 image_04712.jpg\n",
      "  └── 📄 image_04744.jpg\n",
      "  └── 📄 image_04759.jpg\n",
      "  └── 📄 image_04743.jpg\n",
      "\n",
      "📁 ./data/flowers/test/class_098\n",
      "  └── 📄 image_07818.jpg\n",
      "  └── 📄 image_07772.jpg\n",
      "  └── 📄 image_07773.jpg\n",
      "  └── 📄 image_07760.jpg\n",
      "  └── 📄 image_07781.jpg\n",
      "\n",
      "📁 ./data/flowers/test/class_072\n",
      "  └── 📄 image_03628.jpg\n",
      "  └── 📄 image_03633.jpg\n",
      "  └── 📄 image_03597.jpg\n",
      "  └── 📄 image_03556.jpg\n",
      "  └── 📄 image_03550.jpg\n",
      "\n",
      "📁 ./data/flowers/test/class_060\n",
      "  └── 📄 image_02923.jpg\n",
      "  └── 📄 image_02964.jpg\n",
      "  └── 📄 image_02978.jpg\n",
      "  └── 📄 image_02948.jpg\n",
      "  └── 📄 image_03005.jpg\n",
      "\n",
      "📁 ./data/flowers/test/class_084\n",
      "  └── 📄 image_02587.jpg\n",
      "  └── 📄 image_02574.jpg\n",
      "  └── 📄 image_02562.jpg\n",
      "  └── 📄 image_02610.jpg\n",
      "  └── 📄 image_02575.jpg\n",
      "\n",
      "📁 ./data/flowers/test/class_064\n",
      "  └── 📄 image_06097.jpg\n",
      "  └── 📄 image_06131.jpg\n",
      "  └── 📄 image_06108.jpg\n",
      "  └── 📄 image_06143.jpg\n",
      "  └── 📄 image_06134.jpg\n",
      "\n",
      "📁 ./data/flowers/test/class_096\n",
      "  └── 📄 image_07667.jpg\n",
      "  └── 📄 image_07656.jpg\n",
      "  └── 📄 image_07643.jpg\n",
      "  └── 📄 image_07605.jpg\n",
      "  └── 📄 image_07651.jpg\n",
      "\n",
      "📁 ./data/flowers/test/class_069\n",
      "  └── 📄 image_05981.jpg\n",
      "  └── 📄 image_05993.jpg\n",
      "  └── 📄 image_05983.jpg\n",
      "  └── 📄 image_05960.jpg\n",
      "  └── 📄 image_06002.jpg\n",
      "\n",
      "📁 ./data/flowers/test/class_050\n",
      "  └── 📄 image_06548.jpg\n",
      "  └── 📄 image_06341.jpg\n",
      "  └── 📄 image_06566.jpg\n",
      "  └── 📄 image_06567.jpg\n",
      "  └── 📄 image_06551.jpg\n",
      "\n",
      "📁 ./data/flowers/test/class_065\n",
      "  └── 📄 image_03191.jpg\n",
      "  └── 📄 image_03264.jpg\n",
      "  └── 📄 image_03246.jpg\n",
      "  └── 📄 image_03218.jpg\n",
      "  └── 📄 image_03262.jpg\n",
      "\n",
      "📁 ./data/flowers/test/class_017\n",
      "  └── 📄 image_03840.jpg\n",
      "  └── 📄 image_03841.jpg\n",
      "  └── 📄 image_03875.jpg\n",
      "  └── 📄 image_03862.jpg\n",
      "  └── 📄 image_03878.jpg\n",
      "\n",
      "📁 ./data/flowers/test/class_005\n",
      "  └── 📄 image_05169.jpg\n",
      "  └── 📄 image_05195.jpg\n",
      "  └── 📄 image_05211.jpg\n",
      "  └── 📄 image_05209.jpg\n",
      "  └── 📄 image_05170.jpg\n",
      "\n",
      "📁 ./data/flowers/test/class_033\n",
      "  └── 📄 image_06458.jpg\n",
      "  └── 📄 image_06446.jpg\n",
      "  └── 📄 image_06485.jpg\n",
      "  └── 📄 image_06477.jpg\n",
      "  └── 📄 image_06486.jpg\n",
      "\n",
      "📁 ./data/flowers/test/class_059\n",
      "  └── 📄 image_05023.jpg\n",
      "  └── 📄 image_05035.jpg\n",
      "  └── 📄 image_05046.jpg\n",
      "  └── 📄 image_05084.jpg\n",
      "  └── 📄 image_05031.jpg\n",
      "\n",
      "📁 ./data/flowers/test/class_039\n",
      "  └── 📄 image_07043.jpg\n",
      "  └── 📄 image_07018.jpg\n",
      "  └── 📄 image_07037.jpg\n",
      "  └── 📄 image_07007.jpg\n",
      "  └── 📄 image_07036.jpg\n",
      "\n",
      "📁 ./data/flowers/test/class_041\n",
      "  └── 📄 image_02221.jpg\n",
      "  └── 📄 image_02195.jpg\n",
      "  └── 📄 image_02213.jpg\n",
      "  └── 📄 image_02307.jpg\n",
      "  └── 📄 image_02212.jpg\n",
      "\n",
      "📁 ./data/flowers/test/class_067\n",
      "  └── 📄 image_07067.jpg\n",
      "  └── 📄 image_07048.jpg\n",
      "  └── 📄 image_07051.jpg\n",
      "  └── 📄 image_07054.jpg\n",
      "  └── 📄 image_07084.jpg\n",
      "\n",
      "📁 ./data/flowers/test/class_036\n",
      "  └── 📄 image_04382.jpg\n",
      "  └── 📄 image_04344.jpg\n",
      "  └── 📄 image_04336.jpg\n",
      "  └── 📄 image_04393.jpg\n",
      "  └── 📄 image_04365.jpg\n",
      "\n",
      "📁 ./data/flowers/test/class_082\n",
      "  └── 📄 image_01694.jpg\n",
      "  └── 📄 image_01671.jpg\n",
      "  └── 📄 image_01688.jpg\n",
      "  └── 📄 image_01692.jpg\n",
      "  └── 📄 image_01590.jpg\n",
      "\n",
      "📁 ./data/flowers/test/class_015\n",
      "  └── 📄 image_06367.jpg\n",
      "  └── 📄 image_06361.jpg\n",
      "  └── 📄 image_06358.jpg\n",
      "  └── 📄 image_06376.jpg\n",
      "  └── 📄 image_06388.jpg\n",
      "\n",
      "📁 ./data/flowers/test/class_062\n",
      "  └── 📄 image_08184.jpg\n",
      "  └── 📄 image_07283.jpg\n",
      "  └── 📄 image_08186.jpg\n",
      "  └── 📄 image_08181.jpg\n",
      "  └── 📄 image_08153.jpg\n",
      "\n",
      "📁 ./data/flowers/test/class_097\n",
      "  └── 📄 image_07705.jpg\n",
      "  └── 📄 image_07713.jpg\n",
      "  └── 📄 image_07737.jpg\n",
      "  └── 📄 image_07749.jpg\n",
      "  └── 📄 image_07715.jpg\n",
      "\n",
      "📁 ./data/flowers/test/class_009\n",
      "  └── 📄 image_06403.jpg\n",
      "  └── 📄 image_06414.jpg\n",
      "  └── 📄 image_06440.jpg\n",
      "  └── 📄 image_06437.jpg\n",
      "  └── 📄 image_06415.jpg\n",
      "\n",
      "📁 ./data/flowers/test/class_037\n",
      "  └── 📄 image_03738.jpg\n",
      "  └── 📄 image_07287.jpg\n",
      "  └── 📄 image_03764.jpg\n",
      "  └── 📄 image_03750.jpg\n",
      "  └── 📄 image_03791.jpg\n",
      "\n",
      "📁 ./data/flowers/test/class_006\n",
      "  └── 📄 image_07186.jpg\n",
      "  └── 📄 image_07187.jpg\n",
      "  └── 📄 image_07163.jpg\n",
      "  └── 📄 image_07177.jpg\n",
      "  └── 📄 image_07164.jpg\n",
      "\n",
      "📁 ./data/flowers/test/class_057\n",
      "  └── 📄 image_07264.jpg\n",
      "  └── 📄 image_07257.jpg\n",
      "  └── 📄 image_07249.jpg\n",
      "  └── 📄 image_07259.jpg\n",
      "  └── 📄 image_08150.jpg\n",
      "\n",
      "📁 ./data/flowers/test/class_002\n",
      "  └── 📄 image_05095.jpg\n",
      "  └── 📄 image_05099.jpg\n",
      "  └── 📄 image_05129.jpg\n",
      "  └── 📄 image_05127.jpg\n",
      "  └── 📄 image_05087.jpg\n",
      "\n",
      "📁 ./data/flowers/test/class_014\n",
      "  └── 📄 image_06095.jpg\n",
      "  └── 📄 image_06096.jpg\n",
      "  └── 📄 image_06061.jpg\n",
      "  └── 📄 image_06085.jpg\n",
      "  └── 📄 image_06058.jpg\n",
      "\n",
      "📁 ./data/flowers/test/class_042\n",
      "  └── 📄 image_05687.jpg\n",
      "  └── 📄 image_05742.jpg\n",
      "  └── 📄 image_05726.jpg\n",
      "  └── 📄 image_05735.jpg\n",
      "  └── 📄 image_05701.jpg\n",
      "\n",
      "📁 ./data/flowers/test/class_095\n",
      "  └── 📄 image_07542.jpg\n",
      "  └── 📄 image_07554.jpg\n",
      "  └── 📄 image_07489.jpg\n",
      "  └── 📄 image_07538.jpg\n",
      "  └── 📄 image_07522.jpg\n",
      "\n",
      "📁 ./data/flowers/test/class_038\n",
      "  └── 📄 image_05811.jpg\n",
      "  └── 📄 image_05793.jpg\n",
      "  └── 📄 image_05825.jpg\n",
      "  └── 📄 image_05823.jpg\n",
      "  └── 📄 image_05836.jpg\n",
      "\n",
      "📁 ./data/flowers/test/class_077\n",
      "  └── 📄 image_00184.jpg\n",
      "  └── 📄 image_00175.jpg\n",
      "  └── 📄 image_00147.jpg\n",
      "  └── 📄 image_00117.jpg\n",
      "  └── 📄 image_00180.jpg\n",
      "\n",
      "📁 ./data/flowers/test/class_004\n",
      "  └── 📄 image_05677.jpg\n",
      "  └── 📄 image_05675.jpg\n",
      "  └── 📄 image_05639.jpg\n",
      "  └── 📄 image_05683.jpg\n",
      "  └── 📄 image_05664.jpg\n",
      "\n",
      "📁 ./data/flowers/test/class_048\n",
      "  └── 📄 image_04667.jpg\n",
      "  └── 📄 image_04626.jpg\n",
      "  └── 📄 image_04642.jpg\n",
      "  └── 📄 image_04629.jpg\n",
      "  └── 📄 image_04663.jpg\n",
      "\n",
      "📁 ./data/flowers/test/class_020\n",
      "  └── 📄 image_04921.jpg\n",
      "  └── 📄 image_04918.jpg\n",
      "  └── 📄 image_04920.jpg\n",
      "  └── 📄 image_04913.jpg\n",
      "  └── 📄 image_04912.jpg\n",
      "\n",
      "📁 ./data/flowers/test/class_061\n",
      "  └── 📄 image_06252.jpg\n",
      "  └── 📄 image_06292.jpg\n",
      "  └── 📄 image_06288.jpg\n",
      "  └── 📄 image_06259.jpg\n",
      "  └── 📄 image_06271.jpg\n",
      "\n",
      "📁 ./data/flowers/test/class_073\n",
      "  └── 📄 image_00382.jpg\n",
      "  └── 📄 image_00362.jpg\n",
      "  └── 📄 image_00358.jpg\n",
      "  └── 📄 image_00401.jpg\n",
      "  └── 📄 image_00384.jpg\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# List files and folders in the target directory\n",
    "for root, dirs, files in os.walk(target_dir):\n",
    "    print(f\"\\n📁 {root}\")\n",
    "    for d in dirs:\n",
    "        print(f\"  └── 📂 {d}\")\n",
    "    for f in files[:5]: \n",
    "        print(f\"  └── 📄 {f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5443da78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training directory: ./data/flowers/train\n",
      "Validation directory: ./data/flowers/val\n",
      "Test directory: ./data/flowers/test\n",
      "Found 5687 images belonging to 102 classes.\n",
      "Found 1185 images belonging to 102 classes.\n",
      "Found 1317 images belonging to 102 classes.\n",
      "Number of classes: 102\n",
      "Number of training samples: 5687\n",
      "Number of validation samples: 1185\n",
      "Number of test samples: 1317\n",
      "\n",
      "Class mapping sample (first 10 classes):\n",
      "0: class_001\n",
      "1: class_002\n",
      "2: class_003\n",
      "3: class_004\n",
      "4: class_005\n",
      "5: class_006\n",
      "6: class_007\n",
      "7: class_008\n",
      "8: class_009\n",
      "9: class_010\n"
     ]
    }
   ],
   "source": [
    "# Setup directories\n",
    "data_dir = \"./data/flowers\"\n",
    "train_dir = os.path.join(data_dir, 'train')\n",
    "validation_dir = os.path.join(data_dir, 'val')\n",
    "test_dir = os.path.join(data_dir, 'test')\n",
    "\n",
    "# Print paths to verify\n",
    "print(f\"Training directory: {train_dir}\")\n",
    "print(f\"Validation directory: {validation_dir}\")\n",
    "print(f\"Test directory: {test_dir}\")\n",
    "\n",
    "# 1. Enhanced Data Augmentation for more robust feature learning\n",
    "train_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.3,\n",
    "    height_shift_range=0.3,\n",
    "    shear_range=0.3,\n",
    "    zoom_range=0.3,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,  # Many flowers look similar upside down\n",
    "    brightness_range=[0.7, 1.3],\n",
    "    fill_mode='reflect'  # Better for natural images\n",
    ")\n",
    "\n",
    "# Validation generator (no augmentation, just preprocessing)\n",
    "validation_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input\n",
    ")\n",
    "\n",
    "# Test generator (no augmentation, just preprocessing)\n",
    "test_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input\n",
    ")\n",
    "\n",
    "# Set up parameters\n",
    "img_height, img_width = 299, 299  # InceptionV3 input size\n",
    "batch_size = 32\n",
    "\n",
    "# Create training generator\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "# Create validation generator\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "# Create test generator\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "# Print number of classes and samples\n",
    "print(f\"Number of classes: {train_generator.num_classes}\")\n",
    "print(f\"Number of training samples: {train_generator.samples}\")\n",
    "print(f\"Number of validation samples: {validation_generator.samples}\")\n",
    "print(f\"Number of test samples: {test_generator.samples}\")\n",
    "\n",
    "# Class indices mapping for reference\n",
    "class_indices = train_generator.class_indices\n",
    "print(\"\\nClass mapping sample (first 10 classes):\")\n",
    "for i, (class_name, index) in enumerate(list(class_indices.items())[:10]):\n",
    "    print(f\"{index}: {class_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7f5d3e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Feature Visualization Functions\n",
    "def preprocess_image(img_path, target_size=(299, 299)):\n",
    "    \"\"\"Load and preprocess an image for InceptionV3\"\"\"\n",
    "    img = image.load_img(img_path, target_size=target_size)\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    img_array = preprocess_input(img_array)\n",
    "    return img_array\n",
    "\n",
    "def deprocess_image(img):\n",
    "    \"\"\"Convert preprocessed image back to displayable format\"\"\"\n",
    "    img = img.reshape(img.shape[1:])\n",
    "    img = (img + 1.0) * 127.5\n",
    "    img = np.clip(img, 0, 255).astype('uint8')\n",
    "    return img\n",
    "\n",
    "# 3. Feature Diversity Loss - Encourages diverse feature activations in middle layers\n",
    "def feature_diversity_loss(layer_output):\n",
    "    \"\"\"Loss function to encourage diverse feature activations\"\"\"\n",
    "    # Calculate standard deviation across feature maps\n",
    "    feature_std = K.std(layer_output, axis=-1)\n",
    "    # Encourage higher standard deviation (more diverse features)\n",
    "    return -K.mean(feature_std)\n",
    "\n",
    "# 4. Class Activation Mapping\n",
    "def generate_gradcam(model, img_array, layer_name, class_idx):\n",
    "    \"\"\"Generate Grad-CAM visualization for a specific class\"\"\"\n",
    "    # Create a model that maps the input image to the activations of the specified layer and predictions\n",
    "    grad_model = Model(\n",
    "        inputs=model.inputs,\n",
    "        outputs=[model.get_layer(layer_name).output, model.output]\n",
    "    )\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "        conv_outputs, predictions = grad_model(img_array)\n",
    "        loss = predictions[:, class_idx]\n",
    "        \n",
    "    # Extract gradients\n",
    "    grads = tape.gradient(loss, conv_outputs)[0]\n",
    "    \n",
    "    # Average gradients spatially\n",
    "    weights = tf.reduce_mean(grads, axis=(0, 1))\n",
    "    \n",
    "    # Create a weighted combination of filters\n",
    "    cam = tf.reduce_sum(tf.multiply(weights, conv_outputs[0]), axis=-1)\n",
    "    \n",
    "    # Process CAM\n",
    "    cam = tf.maximum(cam, 0)\n",
    "    cam = cam / tf.math.reduce_max(cam)\n",
    "    cam = cam.numpy()\n",
    "    return cam\n",
    "\n",
    "def overlay_gradcam(img_path, cam, target_size=(299, 299)):\n",
    "    \"\"\"Overlay Grad-CAM heatmap on original image\"\"\"\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.resize(img, target_size)\n",
    "    \n",
    "    # Convert CAM to heatmap\n",
    "    heatmap = cv2.applyColorMap(np.uint8(255 * cam), cv2.COLORMAP_JET)\n",
    "    \n",
    "    # Overlay heatmap on original image\n",
    "    overlayed = cv2.addWeighted(img, 0.7, heatmap, 0.3, 0)\n",
    "    return overlayed\n",
    "\n",
    "# 5. Custom Callback for Tracking Layer Activations\n",
    "class FeatureVisualizationCallback(keras.callbacks.Callback):\n",
    "    def __init__(self, validation_data, layer_names, output_dir='feature_viz', freq=2):\n",
    "        super(FeatureVisualizationCallback, self).__init__()\n",
    "        self.validation_data = validation_data\n",
    "        self.layer_names = layer_names\n",
    "        self.output_dir = output_dir\n",
    "        self.freq = freq\n",
    "        if not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir)\n",
    "            \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if (epoch + 1) % self.freq != 0:\n",
    "            return\n",
    "            \n",
    "        # Get a sample batch\n",
    "        x_val, y_val = next(self.validation_data)\n",
    "        \n",
    "        # Create a model to output activations for each layer\n",
    "        layer_outputs = [self.model.get_layer(name).output for name in self.layer_names]\n",
    "        activation_model = Model(inputs=self.model.input, outputs=layer_outputs)\n",
    "        \n",
    "        # Get activations\n",
    "        activations = activation_model.predict(x_val)\n",
    "        \n",
    "        # Visualize activations for each layer\n",
    "        for i, layer_name in enumerate(self.layer_names):\n",
    "            # Create output directory for this layer\n",
    "            layer_dir = os.path.join(self.output_dir, f\"{layer_name}_epoch{epoch+1}\")\n",
    "            if not os.path.exists(layer_dir):\n",
    "                os.makedirs(layer_dir)\n",
    "                \n",
    "            # Get layer activations\n",
    "            layer_activation = activations[i]\n",
    "            \n",
    "            # Visualize feature maps\n",
    "            plt.figure(figsize=(16, 16))\n",
    "            features_per_row = 8\n",
    "            n_features = min(64, layer_activation.shape[-1])\n",
    "            n_rows = n_features // features_per_row\n",
    "            \n",
    "            for j in range(n_features):\n",
    "                plt.subplot(n_rows, features_per_row, j+1)\n",
    "                plt.imshow(layer_activation[0, :, :, j], cmap='viridis')\n",
    "                plt.axis('off')\n",
    "                \n",
    "            plt.tight_layout()\n",
    "            plt.savefig(os.path.join(layer_dir, f\"feature_maps.png\"))\n",
    "            plt.close()\n",
    "            \n",
    "            # For the first sample image, also generate Grad-CAM for the top predicted class\n",
    "            if i == len(self.layer_names) - 1:  # Only do this for the last layer\n",
    "                predicted_class = np.argmax(self.model.predict(x_val[0:1]))\n",
    "                cam = generate_gradcam(self.model, x_val[0:1], layer_name, predicted_class)\n",
    "                \n",
    "                # Reshape CAM to image dimensions\n",
    "                cam_resized = cv2.resize(cam, (img_width, img_height))\n",
    "                \n",
    "                # Save CAM heatmap\n",
    "                plt.figure(figsize=(8, 8))\n",
    "                plt.imshow(cam_resized)\n",
    "                plt.colorbar()\n",
    "                plt.tight_layout()\n",
    "                plt.savefig(os.path.join(layer_dir, f\"gradcam_class{predicted_class}.png\"))\n",
    "                plt.close()\n",
    "\n",
    "# 6. DeepDream Visualization Callback\n",
    "def deepdream(model, img_array, layer_name, iterations=20, step=0.01):\n",
    "    \"\"\"Create a DeepDream image by maximizing activations\"\"\"\n",
    "    # Create a model that outputs the target layer's activations\n",
    "    feature_extractor = Model(inputs=model.input, outputs=model.get_layer(layer_name).output)\n",
    "    \n",
    "    # Define the loss (maximize activations)\n",
    "    def calculate_loss(img):\n",
    "        activation = feature_extractor(img)\n",
    "        return -tf.reduce_mean(activation)\n",
    "    \n",
    "    # Gradient ascent step\n",
    "    @tf.function\n",
    "    def gradient_ascent_step(img, learning_rate):\n",
    "        with tf.GradientTape() as tape:\n",
    "            tape.watch(img)\n",
    "            loss = calculate_loss(img)\n",
    "        \n",
    "        # Calculate gradients\n",
    "        grads = tape.gradient(loss, img)\n",
    "        # Normalize gradients\n",
    "        grads = tf.math.l2_normalize(grads)\n",
    "        # Apply gradients\n",
    "        img += learning_rate * grads\n",
    "        return loss, img\n",
    "    \n",
    "    # Start with the input image\n",
    "    dream_img = tf.convert_to_tensor(img_array)\n",
    "    \n",
    "    # Perform gradient ascent\n",
    "    for i in range(iterations):\n",
    "        loss, dream_img = gradient_ascent_step(dream_img, step)\n",
    "    \n",
    "    # Return the final image\n",
    "    return deprocess_image(dream_img.numpy())\n",
    "\n",
    "class DeepDreamVisualizationCallback(keras.callbacks.Callback):\n",
    "    def __init__(self, test_img_path, layers, output_dir='deepdream_viz', freq=5):\n",
    "        super(DeepDreamVisualizationCallback, self).__init__()\n",
    "        self.test_img = preprocess_image(test_img_path)\n",
    "        self.layers = layers\n",
    "        self.output_dir = output_dir\n",
    "        self.freq = freq\n",
    "        if not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir)\n",
    "            # Save original image for reference\n",
    "            original_img = image.load_img(test_img_path, target_size=(299, 299))\n",
    "            original_img.save(os.path.join(output_dir, 'original_image.jpg'))\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if (epoch + 1) % self.freq != 0:\n",
    "            return\n",
    "            \n",
    "        epoch_dir = os.path.join(self.output_dir, f\"epoch_{epoch+1}\")\n",
    "        if not os.path.exists(epoch_dir):\n",
    "            os.makedirs(epoch_dir)\n",
    "            \n",
    "        for layer_name in self.layers:\n",
    "            print(f\"Generating DeepDream for layer {layer_name} at epoch {epoch+1}\")\n",
    "            try:\n",
    "                # Generate DeepDream for this layer\n",
    "                dream_img = deepdream(\n",
    "                    self.model, \n",
    "                    self.test_img.copy(), \n",
    "                    layer_name,\n",
    "                    iterations=15  # Keep it reasonably fast for monitoring\n",
    "                )\n",
    "                \n",
    "                # Save visualization\n",
    "                Image.fromarray(dream_img).save(os.path.join(epoch_dir, f\"{layer_name}.jpg\"))\n",
    "            except Exception as e:\n",
    "                print(f\"Error generating DeepDream for layer {layer_name}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0f9da8e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1744363935.356227   10235 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 12886 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4080, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using sample image for visualizations: ./data/flowers/train/class_029/image_04099.jpg\n",
      "PHASE 1: Training top layers only...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maiko/miniconda3/envs/cvai/lib/python3.9/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1744363948.203049   12878 service.cc:152] XLA service 0x7f3ba4003590 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1744363948.203388   12878 service.cc:160]   StreamExecutor device (0): NVIDIA GeForce RTX 4080, Compute Capability 8.9\n",
      "2025-04-11 11:32:28.323633: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1744363949.335500   12878 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
      "2025-04-11 11:32:30.274672: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_8401', 204 bytes spill stores, 204 bytes spill loads\n",
      "\n",
      "2025-04-11 11:32:30.391129: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_8401_0', 396 bytes spill stores, 2300 bytes spill loads\n",
      "\n",
      "2025-04-11 11:32:30.549979: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_8621', 84 bytes spill stores, 84 bytes spill loads\n",
      "\n",
      "2025-04-11 11:32:30.552127: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_8408', 896 bytes spill stores, 896 bytes spill loads\n",
      "\n",
      "2025-04-11 11:32:30.586122: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_8408', 632 bytes spill stores, 632 bytes spill loads\n",
      "\n",
      "2025-04-11 11:32:30.633571: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_8408', 120 bytes spill stores, 120 bytes spill loads\n",
      "\n",
      "2025-04-11 11:32:30.680953: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_8401', 3940 bytes spill stores, 3920 bytes spill loads\n",
      "\n",
      "2025-04-11 11:32:30.741718: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_8621', 32 bytes spill stores, 32 bytes spill loads\n",
      "\n",
      "2025-04-11 11:32:30.767848: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_8408', 4264 bytes spill stores, 4244 bytes spill loads\n",
      "\n",
      "2025-04-11 11:32:30.814156: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_8401', 992 bytes spill stores, 992 bytes spill loads\n",
      "\n",
      "2025-04-11 11:32:30.839108: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_8635', 20 bytes spill stores, 20 bytes spill loads\n",
      "\n",
      "2025-04-11 11:32:31.059405: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_8637', 12 bytes spill stores, 12 bytes spill loads\n",
      "\n",
      "2025-04-11 11:32:31.098949: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_8635', 32 bytes spill stores, 32 bytes spill loads\n",
      "\n",
      "2025-04-11 11:32:31.424155: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_8635', 36 bytes spill stores, 44 bytes spill loads\n",
      "\n",
      "2025-04-11 11:32:31.449955: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_8408', 64 bytes spill stores, 64 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  1/177\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m34:41\u001b[0m 12s/step - accuracy: 0.0000e+00 - loss: 4.7990"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1744363957.317017   12878 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 26/177\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m43s\u001b[0m 288ms/step - accuracy: 0.0875 - loss: 4.6290"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 11:32:46.086549: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_8401', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "2025-04-11 11:32:46.264088: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_8401', 220 bytes spill stores, 220 bytes spill loads\n",
      "\n",
      "2025-04-11 11:32:46.395134: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_8408', 740 bytes spill stores, 740 bytes spill loads\n",
      "\n",
      "2025-04-11 11:32:46.434050: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_8408', 1188 bytes spill stores, 1188 bytes spill loads\n",
      "\n",
      "2025-04-11 11:32:46.439891: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_8408_0', 136 bytes spill stores, 136 bytes spill loads\n",
      "\n",
      "2025-04-11 11:32:46.447540: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_8401', 4384 bytes spill stores, 4228 bytes spill loads\n",
      "\n",
      "2025-04-11 11:32:46.616145: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_8401', 1008 bytes spill stores, 1008 bytes spill loads\n",
      "\n",
      "2025-04-11 11:32:46.623299: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_8408', 124 bytes spill stores, 124 bytes spill loads\n",
      "\n",
      "2025-04-11 11:32:46.749064: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_8408', 100 bytes spill stores, 100 bytes spill loads\n",
      "\n",
      "2025-04-11 11:32:46.772785: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_8408', 968 bytes spill stores, 968 bytes spill loads\n",
      "\n",
      "2025-04-11 11:32:46.786320: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_8401', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n",
      "2025-04-11 11:32:46.956512: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_8635', 28 bytes spill stores, 32 bytes spill loads\n",
      "\n",
      "2025-04-11 11:32:47.126725: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_8637', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "2025-04-11 11:32:47.314752: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_8621', 36 bytes spill stores, 36 bytes spill loads\n",
      "\n",
      "2025-04-11 11:32:47.429652: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_8621', 60 bytes spill stores, 60 bytes spill loads\n",
      "\n",
      "2025-04-11 11:32:47.458829: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_8635', 20 bytes spill stores, 20 bytes spill loads\n",
      "\n",
      "2025-04-11 11:32:47.471483: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_8635', 32 bytes spill stores, 32 bytes spill loads\n",
      "\n",
      "2025-04-11 11:32:47.482163: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_8637', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 310ms/step - accuracy: 0.2544 - loss: 3.5101"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 339ms/step - accuracy: 0.2552 - loss: 3.5051 - val_accuracy: 0.6343 - val_loss: 1.3571 - learning_rate: 0.0010\n",
      "Epoch 2/5\n",
      "\u001b[1m  1/177\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - accuracy: 0.6562 - loss: 1.3524"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maiko/miniconda3/envs/cvai/lib/python3.9/site-packages/keras/src/trainers/epoch_iterator.py:107: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self._interrupted_warning()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maiko/miniconda3/envs/cvai/lib/python3.9/site-packages/keras/src/models/functional.py:238: UserWarning: The structure of `inputs` doesn't match the expected structure.\n",
      "Expected: ['keras_tensor']\n",
      "Received: inputs=Tensor(shape=(1, 299, 299, 3))\n",
      "  warnings.warn(msg)\n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 77ms/step - accuracy: 0.6562 - loss: 1.3524 - val_accuracy: 0.6402 - val_loss: 1.3319 - learning_rate: 0.0010\n",
      "Epoch 3/5\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 258ms/step - accuracy: 0.6509 - loss: 1.3141"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 268ms/step - accuracy: 0.6510 - loss: 1.3135 - val_accuracy: 0.7703 - val_loss: 0.8543 - learning_rate: 0.0010\n",
      "Epoch 4/5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/stepaccuracy: 0.7188 - loss: 1.082\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - accuracy: 0.7188 - loss: 1.0822 - val_accuracy: 0.7762 - val_loss: 0.8462 - learning_rate: 0.0010\n",
      "Epoch 5/5\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 261ms/step - accuracy: 0.7426 - loss: 0.9481Generating DeepDream for layer mixed3 at epoch 5\n",
      "Generating DeepDream for layer mixed5 at epoch 5\n",
      "Generating DeepDream for layer mixed7 at epoch 5\n",
      "Generating DeepDream for layer mixed9 at epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 298ms/step - accuracy: 0.7427 - loss: 0.9479 - val_accuracy: 0.8125 - val_loss: 0.6771 - learning_rate: 0.0010\n",
      "\n",
      "PHASE 2: Unfreezing layers from mixed9_1 onwards...\n",
      "Trainable parameters: 2,202,726\n",
      "Non-trainable parameters: 21,802,784\n",
      "Epoch 1/5\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 275ms/step - accuracy: 0.7937 - loss: 0.7277"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 305ms/step - accuracy: 0.7937 - loss: 0.7276 - val_accuracy: 0.8269 - val_loss: 0.5873 - learning_rate: 5.0000e-04\n",
      "Epoch 2/5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/stepaccuracy: 0.7812 - loss: 0.589\n",
      "WARNING:tensorflow:5 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7f39b0663280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7f39b0663280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 57ms/step - accuracy: 0.7812 - loss: 0.5898 - val_accuracy: 0.8328 - val_loss: 0.5754 - learning_rate: 5.0000e-04\n",
      "Epoch 3/5\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 254ms/step - accuracy: 0.8333 - loss: 0.6011"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 264ms/step - accuracy: 0.8333 - loss: 0.6011 - val_accuracy: 0.8395 - val_loss: 0.5481 - learning_rate: 5.0000e-04\n",
      "Epoch 4/5\n",
      "\u001b[1m  1/177\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - accuracy: 0.8750 - loss: 0.5030WARNING:tensorflow:6 out of the last 7 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7f3b1c255550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 7 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7f3b1c255550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 36ms/step - accuracy: 0.8750 - loss: 0.5030 - val_accuracy: 0.8387 - val_loss: 0.5513 - learning_rate: 5.0000e-04\n",
      "Epoch 5/5\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 254ms/step - accuracy: 0.8379 - loss: 0.5392Generating DeepDream for layer mixed3 at epoch 5\n",
      "Generating DeepDream for layer mixed5 at epoch 5\n",
      "Generating DeepDream for layer mixed7 at epoch 5\n",
      "Generating DeepDream for layer mixed9 at epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 290ms/step - accuracy: 0.8379 - loss: 0.5393 - val_accuracy: 0.8606 - val_loss: 0.4639 - learning_rate: 5.0000e-04\n",
      "\n",
      "PHASE 3: Unfreezing layers from mixed9_0 onwards...\n",
      "Trainable parameters: 8,276,262\n",
      "Non-trainable parameters: 15,729,248\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 11:38:39.690943: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_10010_0', 204 bytes spill stores, 420 bytes spill loads\n",
      "\n",
      "2025-04-11 11:38:39.713724: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_10010', 84 bytes spill stores, 84 bytes spill loads\n",
      "\n",
      "2025-04-11 11:38:39.727440: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_10010', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m172/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m1s\u001b[0m 255ms/step - accuracy: 0.8324 - loss: 0.6174"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 11:39:29.167316: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_10010', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "2025-04-11 11:39:29.204759: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_10010', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n",
      "2025-04-11 11:39:29.248208: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_10010_0', 204 bytes spill stores, 444 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 282ms/step - accuracy: 0.8328 - loss: 0.6150"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 310ms/step - accuracy: 0.8329 - loss: 0.6145 - val_accuracy: 0.8682 - val_loss: 0.4164 - learning_rate: 2.0000e-04\n",
      "Epoch 2/5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/stepaccuracy: 0.9688 - loss: 0.170\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 61ms/step - accuracy: 0.9688 - loss: 0.1702 - val_accuracy: 0.8699 - val_loss: 0.4220 - learning_rate: 2.0000e-04\n",
      "Epoch 3/5\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 258ms/step - accuracy: 0.9129 - loss: 0.3001"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 269ms/step - accuracy: 0.9129 - loss: 0.3002 - val_accuracy: 0.9147 - val_loss: 0.2962 - learning_rate: 2.0000e-04\n",
      "Epoch 4/5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/stepaccuracy: 0.9375 - loss: 0.178\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 36ms/step - accuracy: 0.9375 - loss: 0.1783 - val_accuracy: 0.9122 - val_loss: 0.3018 - learning_rate: 2.0000e-04\n",
      "Epoch 5/5\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 259ms/step - accuracy: 0.9279 - loss: 0.2588Generating DeepDream for layer mixed3 at epoch 5\n",
      "Generating DeepDream for layer mixed5 at epoch 5\n",
      "Generating DeepDream for layer mixed7 at epoch 5\n",
      "Generating DeepDream for layer mixed9 at epoch 5\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 291ms/step - accuracy: 0.9279 - loss: 0.2587 - val_accuracy: 0.9012 - val_loss: 0.3191 - learning_rate: 2.0000e-04\n",
      "\n",
      "PHASE 4: Unfreezing layers from mixed9 onwards...\n",
      "Trainable parameters: 8,276,262\n",
      "Non-trainable parameters: 15,729,248\n",
      "Adding feature diversity loss for mid-level layers...\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "y_true and y_pred have different structures.\ny_true: *\ny_pred: ['*', '*']\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 146\u001b[0m\n\u001b[1;32m    132\u001b[0m     model\u001b[38;5;241m.\u001b[39mcompile(\n\u001b[1;32m    133\u001b[0m         optimizer\u001b[38;5;241m=\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39mlr),\n\u001b[1;32m    134\u001b[0m         loss\u001b[38;5;241m=\u001b[39m{\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    142\u001b[0m         metrics\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdense\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m]}\n\u001b[1;32m    143\u001b[0m     )\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;66;03m# For this phase, fit with both outputs\u001b[39;00m\n\u001b[0;32m--> 146\u001b[0m     history_phase \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[43m        \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_generator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msamples\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_generator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msamples\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[43m        \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    152\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\n\u001b[1;32m    153\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m     \u001b[38;5;66;03m# Standard training for other phases\u001b[39;00m\n\u001b[1;32m    156\u001b[0m     model\u001b[38;5;241m.\u001b[39mcompile(\n\u001b[1;32m    157\u001b[0m         optimizer\u001b[38;5;241m=\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39mlr),\n\u001b[1;32m    158\u001b[0m         loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    159\u001b[0m         metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    160\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/cvai/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniconda3/envs/cvai/lib/python3.9/site-packages/keras/src/trainers/compile_utils.py:754\u001b[0m, in \u001b[0;36mCompileLoss.call\u001b[0;34m(self, y_true, y_pred, sample_weight)\u001b[0m\n\u001b[1;32m    748\u001b[0m                 y_true_struct \u001b[38;5;241m=\u001b[39m tree\u001b[38;5;241m.\u001b[39mmap_structure(\n\u001b[1;32m    749\u001b[0m                     \u001b[38;5;28;01mlambda\u001b[39;00m _: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m\"\u001b[39m, y_true\n\u001b[1;32m    750\u001b[0m                 )\n\u001b[1;32m    751\u001b[0m                 y_pred_struct \u001b[38;5;241m=\u001b[39m tree\u001b[38;5;241m.\u001b[39mmap_structure(\n\u001b[1;32m    752\u001b[0m                     \u001b[38;5;28;01mlambda\u001b[39;00m _: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m\"\u001b[39m, y_pred\n\u001b[1;32m    753\u001b[0m                 )\n\u001b[0;32m--> 754\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    755\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true and y_pred have different structures.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    756\u001b[0m                     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my_true_struct\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    757\u001b[0m                     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_pred: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my_pred_struct\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    758\u001b[0m                 )\n\u001b[1;32m    760\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuilt:\n\u001b[1;32m    761\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuild(y_true, y_pred)\n",
      "\u001b[0;31mValueError\u001b[0m: y_true and y_pred have different structures.\ny_true: *\ny_pred: ['*', '*']\n"
     ]
    }
   ],
   "source": [
    "base_model = InceptionV3(weights='imagenet', include_top=False)\n",
    "\n",
    "# Add a global spatial average pooling layer\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "# Add a fully-connected layer\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "\n",
    "# Add a final output layer with softmax for classification\n",
    "predictions = Dense(train_generator.num_classes, activation='softmax')(x)\n",
    "\n",
    "# Create the main model\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Select a representative flower image for visualization\n",
    "# You should replace this with an actual path to a flower image\n",
    "sample_img_path = os.path.join(train_dir, os.listdir(train_dir)[0], os.listdir(os.path.join(train_dir, os.listdir(train_dir)[0]))[0])\n",
    "print(f\"Using sample image for visualizations: {sample_img_path}\")\n",
    "\n",
    "# Setup callbacks\n",
    "monitor_layers = ['mixed3', 'mixed5', 'mixed7', 'mixed9']\n",
    "\n",
    "feature_viz_callback = FeatureVisualizationCallback(\n",
    "    validation_generator,\n",
    "    monitor_layers,\n",
    "    output_dir='feature_viz',\n",
    "    freq=2\n",
    ")\n",
    "\n",
    "deepdream_callback = DeepDreamVisualizationCallback(\n",
    "    sample_img_path,\n",
    "    monitor_layers,\n",
    "    output_dir='deepdream_viz',\n",
    "    freq=5\n",
    ")\n",
    "\n",
    "# Regular training callbacks\n",
    "checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
    "    'flower_model_checkpoint_{epoch:02d}.h5',\n",
    "    save_best_only=True,\n",
    "    monitor='val_accuracy'\n",
    ")\n",
    "\n",
    "reduce_lr_callback = keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,\n",
    "    patience=3,\n",
    "    min_lr=1e-6\n",
    ")\n",
    "\n",
    "callbacks = [\n",
    "    feature_viz_callback,\n",
    "    deepdream_callback,\n",
    "    checkpoint_callback,\n",
    "    reduce_lr_callback\n",
    "]\n",
    "\n",
    "# ----- TRAINING PROCESS -----\n",
    "\n",
    "# STEP 1: Train only the top layers with all base model layers frozen\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), \n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(\"PHASE 1: Training top layers only...\")\n",
    "history_1 = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // batch_size,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples // batch_size,\n",
    "    epochs=5,\n",
    "    callbacks=callbacks\n",
    ")\n",
    "\n",
    "# STEP 2: Progressive Layer Unfreezing - One block at a time\n",
    "# Get all the mixed layer names to use as reference points\n",
    "mixed_layers = [layer.name for layer in base_model.layers if 'mixed' in layer.name]\n",
    "mixed_layers.sort()  # Sort in ascending order from bottom to top\n",
    "\n",
    "histories = [history_1]  # Keep track of training history\n",
    "\n",
    "# Define the progressive unfreezing schedule - starting from the top\n",
    "unfreezing_schedule = [\n",
    "    mixed_layers[-1],  # mixed10\n",
    "    mixed_layers[-2],  # mixed9\n",
    "    mixed_layers[-3],  # mixed8\n",
    "    mixed_layers[-4],  # mixed7\n",
    "]\n",
    "\n",
    "# Create a model with feature diversity loss for mid-level layers\n",
    "# We'll use 'mixed7' as our feature diversity target\n",
    "feature_layer = base_model.get_layer('mixed7').output\n",
    "aux_output = Lambda(lambda x: x, name='feature_layer')(feature_layer)\n",
    "\n",
    "# Create a model with multiple outputs\n",
    "model_with_aux = Model(\n",
    "    inputs=base_model.input, \n",
    "    outputs=[predictions, aux_output]\n",
    ")\n",
    "\n",
    "# Learning rate schedule - decrease as we unfreeze deeper layers\n",
    "lr_schedule = [5e-4, 2e-4, 1e-4, 5e-5]\n",
    "\n",
    "# Progressively unfreeze layers and train\n",
    "for phase, (target_layer, lr) in enumerate(zip(unfreezing_schedule, lr_schedule), start=2):\n",
    "    print(f\"\\nPHASE {phase}: Unfreezing layers from {target_layer} onwards...\")\n",
    "    \n",
    "    # Reset all layers to trainable\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = True\n",
    "    \n",
    "    # Then freeze everything before the target layer\n",
    "    target_idx = [i for i, layer in enumerate(base_model.layers) if layer.name == target_layer][0]\n",
    "    for layer in base_model.layers[:target_idx]:\n",
    "        layer.trainable = False\n",
    "        \n",
    "    # Count trainable parameters\n",
    "    trainable_count = np.sum([K.count_params(w) for w in model.trainable_weights])\n",
    "    non_trainable_count = np.sum([K.count_params(w) for w in model.non_trainable_weights])\n",
    "    print(f\"Trainable parameters: {trainable_count:,}\")\n",
    "    print(f\"Non-trainable parameters: {non_trainable_count:,}\")\n",
    "    \n",
    "    # For the middle layers, use the feature diversity loss\n",
    "    if phase == 4:  # When we're unfreezing mixed7\n",
    "        print(\"Adding feature diversity loss for mid-level layers...\")\n",
    "        model = model_with_aux\n",
    "        model.compile(\n",
    "            optimizer=Adam(learning_rate=lr),\n",
    "            loss={\n",
    "                'dense': 'categorical_crossentropy',\n",
    "                'feature_layer': feature_diversity_loss\n",
    "            },\n",
    "            loss_weights={\n",
    "                'dense': 1.0,\n",
    "                'feature_layer': 0.2  # Weight for the feature diversity loss\n",
    "            },\n",
    "            metrics={'dense': ['accuracy']}\n",
    "        )\n",
    "        \n",
    "        # For this phase, fit with both outputs\n",
    "        history_phase = model.fit(\n",
    "            train_generator,\n",
    "            steps_per_epoch=train_generator.samples // batch_size,\n",
    "            validation_data=validation_generator,\n",
    "            validation_steps=validation_generator.samples // batch_size,\n",
    "            epochs=5,\n",
    "            callbacks=callbacks\n",
    "        )\n",
    "    else:\n",
    "        # Standard training for other phases\n",
    "        model.compile(\n",
    "            optimizer=Adam(learning_rate=lr),\n",
    "            loss='categorical_crossentropy',\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "        \n",
    "        history_phase = model.fit(\n",
    "            train_generator,\n",
    "            steps_per_epoch=train_generator.samples // batch_size,\n",
    "            validation_data=validation_generator,\n",
    "            validation_steps=validation_generator.samples // batch_size,\n",
    "            epochs=5,\n",
    "            callbacks=callbacks\n",
    "        )\n",
    "    \n",
    "    # Save history for plotting\n",
    "    histories.append(history_phase)\n",
    "\n",
    "# STEP 3: Final Fine-tuning Phase - All Layers\n",
    "print(\"\\nPHASE FINAL: Fine-tuning all layers with very low learning rate...\")\n",
    "\n",
    "# Make all layers trainable for final tuning\n",
    "for layer in model.layers:\n",
    "    layer.trainable = True\n",
    "\n",
    "# Very low learning rate for final fine-tuning\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=1e-5),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "history_final = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // batch_size,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples // batch_size,\n",
    "    epochs=5,\n",
    "    callbacks=callbacks\n",
    ")\n",
    "\n",
    "histories.append(history_final)\n",
    "\n",
    "# Save the final fine-tuned model\n",
    "model.save('flower_finetuned_inceptionv3_enhanced.h5')\n",
    "\n",
    "# Function to plot combined training history\n",
    "def plot_training_history(histories):\n",
    "    # Combined histories\n",
    "    acc = []\n",
    "    val_acc = []\n",
    "    loss = []\n",
    "    val_loss = []\n",
    "    \n",
    "    # Combine histories, accounting for multiple output model\n",
    "    for history in histories:\n",
    "        if 'accuracy' in history.history:\n",
    "            acc.extend(history.history['accuracy'])\n",
    "            val_acc.extend(history.history['val_accuracy'])\n",
    "            loss.extend(history.history['loss'])\n",
    "            val_loss.extend(history.history['val_loss'])\n",
    "        elif 'dense_accuracy' in history.history:\n",
    "            # For the model with multiple outputs\n",
    "            acc.extend(history.history['dense_accuracy'])\n",
    "            val_acc.extend(history.history['val_dense_accuracy'])\n",
    "            loss.extend(history.history['loss'])\n",
    "            val_loss.extend(history.history['val_loss'])\n",
    "    \n",
    "    epochs_range = range(len(acc))\n",
    "    \n",
    "    plt.figure(figsize=(15, 7))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "    plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "    plt.axvline(x=5, color='r', linestyle='--', label='Phase 1')\n",
    "    plt.axvline(x=10, color='g', linestyle='--', label='Phase 2')\n",
    "    plt.axvline(x=15, color='b', linestyle='--', label='Phase 3')\n",
    "    plt.axvline(x=20, color='m', linestyle='--', label='Phase 4')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs_range, loss, label='Training Loss')\n",
    "    plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "    plt.axvline(x=5, color='r', linestyle='--', label='Phase 1')\n",
    "    plt.axvline(x=10, color='g', linestyle='--', label='Phase 2')\n",
    "    plt.axvline(x=15, color='b', linestyle='--', label='Phase 3')\n",
    "    plt.axvline(x=20, color='m', linestyle='--', label='Phase 4')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('enhanced_training_history.png')\n",
    "    plt.show()\n",
    "\n",
    "# Plot the training history\n",
    "plot_training_history(histories)\n",
    "\n",
    "# Function to analyze which layers contain the most flower-specific features\n",
    "def analyze_flower_features(model, class_idx=None):\n",
    "    \"\"\"\n",
    "    Analyzes model layers to find those with the strongest flower feature activations\n",
    "    \n",
    "    Parameters:\n",
    "    - model: The trained model\n",
    "    - class_idx: Optional specific flower class to analyze\n",
    "    \n",
    "    Returns:\n",
    "    - Dictionary with layer rankings\n",
    "    \"\"\"\n",
    "    # Get a few flower images\n",
    "    flower_batch = next(train_generator)[0]\n",
    "    \n",
    "    # List of layers to analyze (focus on mixed layers)\n",
    "    layers_to_analyze = [layer.name for layer in model.layers if 'mixed' in layer.name]\n",
    "    \n",
    "    # Store results\n",
    "    layer_stats = {}\n",
    "    \n",
    "    # For each layer, measure activations\n",
    "    for layer_name in layers_to_analyze:\n",
    "        print(f\"Analyzing layer: {layer_name}\")\n",
    "        layer_model = Model(inputs=model.input, outputs=model.get_layer(layer_name).output)\n",
    "        \n",
    "        # Get activations for the batch\n",
    "        activations = layer_model.predict(flower_batch)\n",
    "        \n",
    "        # Calculate statistics\n",
    "        mean_activation = np.mean(activations)\n",
    "        max_activation = np.max(activations)\n",
    "        std_activation = np.std(activations)\n",
    "        \n",
    "        # Store results\n",
    "        layer_stats[layer_name] = {\n",
    "            'mean': float(mean_activation),\n",
    "            'max': float(max_activation),\n",
    "            'std': float(std_activation)\n",
    "        }\n",
    "    \n",
    "    # Sort layers by mean activation (higher is better for feature representation)\n",
    "    sorted_layers = sorted(layer_stats.items(), key=lambda x: x[1]['mean'], reverse=True)\n",
    "    \n",
    "    print(\"\\nLayers ranked by activation strength (higher mean = stronger flower features):\")\n",
    "    for i, (layer_name, stats) in enumerate(sorted_layers):\n",
    "        print(f\"{i+1}. {layer_name}: Mean={stats['mean']:.6f}, Max={stats['max']:.6f}, Std={stats['std']:.6f}\")\n",
    "    \n",
    "    return layer_stats\n",
    "\n",
    "# Analyze which layers contain the most flower-specific features\n",
    "print(\"\\nAnalyzing which layers contain the strongest flower feature representations...\")\n",
    "layer_stats = analyze_flower_features(model)\n",
    "\n",
    "print(\"\\nTraining complete! Model saved as 'flower_finetuned_inceptionv3_enhanced.h5'\")\n",
    "print(\"This model has been optimized for strong flower feature representations across layers.\")\n",
    "print(\"For DeepDream, recommend using the top layers from the analysis above.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "909a326e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training directory: ./data/flowers/train\n",
      "Validation directory: ./data/flowers/val\n",
      "Test directory: ./data/flowers/test\n",
      "Found 5687 images belonging to 102 classes.\n",
      "Found 1185 images belonging to 102 classes.\n",
      "Found 1317 images belonging to 102 classes.\n",
      "Number of classes: 102\n",
      "Number of training samples: 5687\n",
      "Number of validation samples: 1185\n",
      "Number of test samples: 1317\n",
      "\n",
      "Class mapping sample (first 10 classes):\n",
      "0: class_001\n",
      "1: class_002\n",
      "2: class_003\n",
      "3: class_004\n",
      "4: class_005\n",
      "5: class_006\n",
      "6: class_007\n",
      "7: class_008\n",
      "8: class_009\n",
      "9: class_010\n",
      "Using sample image for visualizations: ./data/flowers/train/class_029/image_04099.jpg\n",
      "PHASE 1: Training top layers only...\n",
      "Epoch 1/5\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 270ms/step - accuracy: 0.2412 - loss: 3.5488"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 298ms/step - accuracy: 0.2421 - loss: 3.5437 - val_accuracy: 0.6478 - val_loss: 1.3691 - learning_rate: 0.0010\n",
      "Epoch 2/5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/stepaccuracy: 0.5000 - loss: 1.660\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maiko/miniconda3/envs/cvai/lib/python3.9/site-packages/keras/src/models/functional.py:238: UserWarning: The structure of `inputs` doesn't match the expected structure.\n",
      "Expected: ['keras_tensor_317']\n",
      "Received: inputs=Tensor(shape=(1, 299, 299, 3))\n",
      "  warnings.warn(msg)\n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 58ms/step - accuracy: 0.5000 - loss: 1.6600 - val_accuracy: 0.6520 - val_loss: 1.3551 - learning_rate: 0.0010\n",
      "Epoch 3/5\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 254ms/step - accuracy: 0.6328 - loss: 1.3565"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 264ms/step - accuracy: 0.6329 - loss: 1.3560 - val_accuracy: 0.7534 - val_loss: 0.8999 - learning_rate: 0.0010\n",
      "Epoch 4/5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/stepaccuracy: 0.5938 - loss: 1.169\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 39ms/step - accuracy: 0.5938 - loss: 1.1695 - val_accuracy: 0.7593 - val_loss: 0.8923 - learning_rate: 0.0010\n",
      "Epoch 5/5\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 258ms/step - accuracy: 0.7374 - loss: 0.9787Generating DeepDream for layer mixed3 at epoch 5\n",
      "Generating DeepDream for layer mixed5 at epoch 5\n",
      "Generating DeepDream for layer mixed7 at epoch 5\n",
      "Generating DeepDream for layer mixed9 at epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 292ms/step - accuracy: 0.7374 - loss: 0.9785 - val_accuracy: 0.7922 - val_loss: 0.7339 - learning_rate: 0.0010\n",
      "\n",
      "PHASE 2: Unfreezing layers from mixed9_1 onwards...\n",
      "Trainable parameters: 2,202,726\n",
      "Non-trainable parameters: 21,802,784\n",
      "Epoch 1/5\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 268ms/step - accuracy: 0.7943 - loss: 0.7580"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 295ms/step - accuracy: 0.7944 - loss: 0.7576 - val_accuracy: 0.8336 - val_loss: 0.5846 - learning_rate: 5.0000e-04\n",
      "Epoch 2/5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/stepaccuracy: 0.9375 - loss: 0.367\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 52ms/step - accuracy: 0.9375 - loss: 0.3672 - val_accuracy: 0.8319 - val_loss: 0.5884 - learning_rate: 5.0000e-04\n",
      "Epoch 3/5\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 252ms/step - accuracy: 0.8347 - loss: 0.5816"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 263ms/step - accuracy: 0.8347 - loss: 0.5816 - val_accuracy: 0.8412 - val_loss: 0.5427 - learning_rate: 5.0000e-04\n",
      "Epoch 4/5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/stepaccuracy: 0.8125 - loss: 0.865\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 44ms/step - accuracy: 0.8125 - loss: 0.8658 - val_accuracy: 0.8438 - val_loss: 0.5408 - learning_rate: 5.0000e-04\n",
      "Epoch 5/5\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 251ms/step - accuracy: 0.8436 - loss: 0.5677Generating DeepDream for layer mixed3 at epoch 5\n",
      "Generating DeepDream for layer mixed5 at epoch 5\n",
      "Generating DeepDream for layer mixed7 at epoch 5\n",
      "Generating DeepDream for layer mixed9 at epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 283ms/step - accuracy: 0.8436 - loss: 0.5676 - val_accuracy: 0.8522 - val_loss: 0.5089 - learning_rate: 5.0000e-04\n",
      "\n",
      "PHASE 3: Unfreezing layers from mixed9_0 onwards...\n",
      "Trainable parameters: 8,276,262\n",
      "Non-trainable parameters: 15,729,248\n",
      "Epoch 1/5\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 279ms/step - accuracy: 0.8272 - loss: 0.6300"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 306ms/step - accuracy: 0.8274 - loss: 0.6294 - val_accuracy: 0.8792 - val_loss: 0.3947 - learning_rate: 2.0000e-04\n",
      "Epoch 2/5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/stepaccuracy: 0.9062 - loss: 0.362\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 58ms/step - accuracy: 0.9062 - loss: 0.3623 - val_accuracy: 0.8843 - val_loss: 0.3948 - learning_rate: 2.0000e-04\n",
      "Epoch 3/5\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 264ms/step - accuracy: 0.8996 - loss: 0.3400"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 276ms/step - accuracy: 0.8996 - loss: 0.3400 - val_accuracy: 0.9003 - val_loss: 0.3355 - learning_rate: 2.0000e-04\n",
      "Epoch 4/5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/stepaccuracy: 0.8125 - loss: 0.373\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 37ms/step - accuracy: 0.8125 - loss: 0.3735 - val_accuracy: 0.8995 - val_loss: 0.3370 - learning_rate: 2.0000e-04\n",
      "Epoch 5/5\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 259ms/step - accuracy: 0.9282 - loss: 0.2669Generating DeepDream for layer mixed3 at epoch 5\n",
      "Generating DeepDream for layer mixed5 at epoch 5\n",
      "Generating DeepDream for layer mixed7 at epoch 5\n",
      "Generating DeepDream for layer mixed9 at epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 294ms/step - accuracy: 0.9281 - loss: 0.2669 - val_accuracy: 0.9046 - val_loss: 0.3202 - learning_rate: 2.0000e-04\n",
      "\n",
      "PHASE 4: Unfreezing layers from mixed9 onwards...\n",
      "Trainable parameters: 8,276,262\n",
      "Non-trainable parameters: 15,729,248\n",
      "Adding feature diversity regularization for mid-level layers...\n",
      "Epoch 1/5\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 298ms/step - accuracy: 0.9475 - loss: 0.1779"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 326ms/step - accuracy: 0.9475 - loss: 0.1779 - val_accuracy: 0.9215 - val_loss: 0.2465 - learning_rate: 1.0000e-04\n",
      "Epoch 2/5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9375 - loss: 0.195\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 56ms/step - accuracy: 0.9375 - loss: 0.1951 - val_accuracy: 0.9223 - val_loss: 0.2480 - learning_rate: 1.0000e-04\n",
      "Epoch 3/5\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 266ms/step - accuracy: 0.9631 - loss: 0.1351"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 277ms/step - accuracy: 0.9631 - loss: 0.1351 - val_accuracy: 0.9274 - val_loss: 0.2310 - learning_rate: 1.0000e-04\n",
      "Epoch 4/5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.9375 - loss: 0.105\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 49ms/step - accuracy: 0.9375 - loss: 0.1051 - val_accuracy: 0.9282 - val_loss: 0.2312 - learning_rate: 1.0000e-04\n",
      "Epoch 5/5\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 262ms/step - accuracy: 0.9643 - loss: 0.1190Generating DeepDream for layer mixed3 at epoch 5\n",
      "Generating DeepDream for layer mixed5 at epoch 5\n",
      "Generating DeepDream for layer mixed7 at epoch 5\n",
      "Generating DeepDream for layer mixed9 at epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 300ms/step - accuracy: 0.9643 - loss: 0.1190 - val_accuracy: 0.9333 - val_loss: 0.2066 - learning_rate: 1.0000e-04\n",
      "\n",
      "PHASE 5: Unfreezing layers from mixed8 onwards...\n",
      "Trainable parameters: 13,317,606\n",
      "Non-trainable parameters: 10,687,904\n",
      "Epoch 1/5\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 280ms/step - accuracy: 0.9415 - loss: 0.1998"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 313ms/step - accuracy: 0.9416 - loss: 0.1997 - val_accuracy: 0.9358 - val_loss: 0.2047 - learning_rate: 5.0000e-05\n",
      "Epoch 2/5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/stepaccuracy: 1.0000 - loss: 0.077\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 0.0774 - val_accuracy: 0.9383 - val_loss: 0.2041 - learning_rate: 5.0000e-05\n",
      "Epoch 3/5\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 256ms/step - accuracy: 0.9723 - loss: 0.0980"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 268ms/step - accuracy: 0.9723 - loss: 0.0980 - val_accuracy: 0.9434 - val_loss: 0.1838 - learning_rate: 5.0000e-05\n",
      "Epoch 4/5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/stepaccuracy: 0.9688 - loss: 0.135\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 47ms/step - accuracy: 0.9688 - loss: 0.1354 - val_accuracy: 0.9434 - val_loss: 0.1837 - learning_rate: 5.0000e-05\n",
      "Epoch 5/5\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 257ms/step - accuracy: 0.9791 - loss: 0.0897Generating DeepDream for layer mixed3 at epoch 5\n",
      "Generating DeepDream for layer mixed5 at epoch 5\n",
      "Generating DeepDream for layer mixed7 at epoch 5\n",
      "Generating DeepDream for layer mixed9 at epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 296ms/step - accuracy: 0.9791 - loss: 0.0897 - val_accuracy: 0.9502 - val_loss: 0.1747 - learning_rate: 5.0000e-05\n",
      "\n",
      "PHASE FINAL: Fine-tuning all layers with very low learning rate...\n",
      "Epoch 1/5\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 381ms/step - accuracy: 0.8901 - loss: 0.3645 - val_accuracy: 0.9392 - val_loss: 0.2052 - learning_rate: 1.0000e-05\n",
      "Epoch 2/5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step accuracy: 1.0000 - loss: 0.054\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 56ms/step - accuracy: 1.0000 - loss: 0.0547 - val_accuracy: 0.9400 - val_loss: 0.2022 - learning_rate: 1.0000e-05\n",
      "Epoch 3/5\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 269ms/step - accuracy: 0.9529 - loss: 0.1617 - val_accuracy: 0.9383 - val_loss: 0.1966 - learning_rate: 1.0000e-05\n",
      "Epoch 4/5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step accuracy: 0.9375 - loss: 0.141\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 47ms/step - accuracy: 0.9375 - loss: 0.1412 - val_accuracy: 0.9375 - val_loss: 0.1965 - learning_rate: 1.0000e-05\n",
      "Epoch 5/5\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 263ms/step - accuracy: 0.9609 - loss: 0.1386Generating DeepDream for layer mixed3 at epoch 5\n",
      "Generating DeepDream for layer mixed5 at epoch 5\n",
      "Generating DeepDream for layer mixed7 at epoch 5\n",
      "Generating DeepDream for layer mixed9 at epoch 5\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 300ms/step - accuracy: 0.9609 - loss: 0.1386 - val_accuracy: 0.9451 - val_loss: 0.1852 - learning_rate: 1.0000e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x700 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analyzing which layers contain the strongest flower feature representations...\n",
      "Analyzing layer: mixed0\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 626ms/step\n",
      "Analyzing layer: mixed1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 931ms/step\n",
      "Analyzing layer: mixed2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "Analyzing layer: mixed3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "Analyzing layer: mixed4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "Analyzing layer: mixed5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "Analyzing layer: mixed6\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "Analyzing layer: mixed7\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "Analyzing layer: mixed8\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Analyzing layer: mixed9_0\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "Analyzing layer: mixed9\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Analyzing layer: mixed9_1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "Analyzing layer: mixed10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "\n",
      "Layers ranked by activation strength (higher mean = stronger flower features):\n",
      "1. mixed0: Mean=0.675856, Max=18.149286, Std=1.133664\n",
      "2. mixed1: Mean=0.502341, Max=17.254036, Std=0.912516\n",
      "3. mixed3: Mean=0.459701, Max=14.990726, Std=0.736139\n",
      "4. mixed2: Mean=0.317931, Max=10.062639, Std=0.643793\n",
      "5. mixed10: Mean=0.297672, Max=23.761265, Std=0.645139\n",
      "6. mixed9_1: Mean=0.278271, Max=23.761265, Std=0.715931\n",
      "7. mixed4: Mean=0.207905, Max=39.105869, Std=0.492472\n",
      "8. mixed5: Mean=0.198087, Max=25.907272, Std=0.491517\n",
      "9. mixed6: Mean=0.187034, Max=21.252136, Std=0.463136\n",
      "10. mixed8: Mean=0.185598, Max=19.612223, Std=0.420317\n",
      "11. mixed7: Mean=0.059026, Max=16.946009, Std=0.252187\n",
      "12. mixed9: Mean=0.051633, Max=15.101952, Std=0.218655\n",
      "13. mixed9_0: Mean=0.046865, Max=7.575514, Std=0.209911\n",
      "\n",
      "Training complete! Model saved as 'flower_finetuned_inceptionv3_enhanced.h5'\n",
      "This model has been optimized for strong flower feature representations across layers.\n",
      "For DeepDream, recommend using the top layers from the analysis above.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Lambda\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras import backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "# Setup directories\n",
    "data_dir = \"./data/flowers\"\n",
    "train_dir = os.path.join(data_dir, 'train')\n",
    "validation_dir = os.path.join(data_dir, 'val')\n",
    "test_dir = os.path.join(data_dir, 'test')\n",
    "\n",
    "# Print paths to verify\n",
    "print(f\"Training directory: {train_dir}\")\n",
    "print(f\"Validation directory: {validation_dir}\")\n",
    "print(f\"Test directory: {test_dir}\")\n",
    "\n",
    "# 1. Enhanced Data Augmentation for more robust feature learning\n",
    "train_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.3,\n",
    "    height_shift_range=0.3,\n",
    "    shear_range=0.3,\n",
    "    zoom_range=0.3,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,  # Many flowers look similar upside down\n",
    "    brightness_range=[0.7, 1.3],\n",
    "    fill_mode='reflect'  # Better for natural images\n",
    ")\n",
    "\n",
    "# Validation generator (no augmentation, just preprocessing)\n",
    "validation_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input\n",
    ")\n",
    "\n",
    "# Test generator (no augmentation, just preprocessing)\n",
    "test_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input\n",
    ")\n",
    "\n",
    "# Set up parameters\n",
    "img_height, img_width = 299, 299  # InceptionV3 input size\n",
    "batch_size = 32\n",
    "\n",
    "# Create training generator\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "# Create validation generator\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "# Create test generator\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "# Print number of classes and samples\n",
    "print(f\"Number of classes: {train_generator.num_classes}\")\n",
    "print(f\"Number of training samples: {train_generator.samples}\")\n",
    "print(f\"Number of validation samples: {validation_generator.samples}\")\n",
    "print(f\"Number of test samples: {test_generator.samples}\")\n",
    "\n",
    "# Class indices mapping for reference\n",
    "class_indices = train_generator.class_indices\n",
    "print(\"\\nClass mapping sample (first 10 classes):\")\n",
    "for i, (class_name, index) in enumerate(list(class_indices.items())[:10]):\n",
    "    print(f\"{index}: {class_name}\")\n",
    "\n",
    "# 2. Feature Visualization Functions\n",
    "def preprocess_image(img_path, target_size=(299, 299)):\n",
    "    \"\"\"Load and preprocess an image for InceptionV3\"\"\"\n",
    "    img = image.load_img(img_path, target_size=target_size)\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    img_array = preprocess_input(img_array)\n",
    "    return img_array\n",
    "\n",
    "def deprocess_image(img):\n",
    "    \"\"\"Convert preprocessed image back to displayable format\"\"\"\n",
    "    img = img.reshape(img.shape[1:])\n",
    "    img = (img + 1.0) * 127.5\n",
    "    img = np.clip(img, 0, 255).astype('uint8')\n",
    "    return img\n",
    "\n",
    "# 3. Feature Diversity Loss - Encourages diverse feature activations in middle layers\n",
    "def feature_diversity_loss(layer_output):\n",
    "    \"\"\"Loss function to encourage diverse feature activations\"\"\"\n",
    "    # Calculate standard deviation across feature maps\n",
    "    feature_std = K.std(layer_output, axis=-1)\n",
    "    # Encourage higher standard deviation (more diverse features)\n",
    "    return -K.mean(feature_std)\n",
    "\n",
    "# 4. Class Activation Mapping\n",
    "def generate_gradcam(model, img_array, layer_name, class_idx):\n",
    "    \"\"\"Generate Grad-CAM visualization for a specific class\"\"\"\n",
    "    # Create a model that maps the input image to the activations of the specified layer and predictions\n",
    "    grad_model = Model(\n",
    "        inputs=model.inputs,\n",
    "        outputs=[model.get_layer(layer_name).output, model.output]\n",
    "    )\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "        conv_outputs, predictions = grad_model(img_array)\n",
    "        loss = predictions[:, class_idx]\n",
    "        \n",
    "    # Extract gradients\n",
    "    grads = tape.gradient(loss, conv_outputs)[0]\n",
    "    \n",
    "    # Average gradients spatially\n",
    "    weights = tf.reduce_mean(grads, axis=(0, 1))\n",
    "    \n",
    "    # Create a weighted combination of filters\n",
    "    cam = tf.reduce_sum(tf.multiply(weights, conv_outputs[0]), axis=-1)\n",
    "    \n",
    "    # Process CAM\n",
    "    cam = tf.maximum(cam, 0)\n",
    "    cam = cam / tf.math.reduce_max(cam)\n",
    "    cam = cam.numpy()\n",
    "    return cam\n",
    "\n",
    "def overlay_gradcam(img_path, cam, target_size=(299, 299)):\n",
    "    \"\"\"Overlay Grad-CAM heatmap on original image\"\"\"\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.resize(img, target_size)\n",
    "    \n",
    "    # Convert CAM to heatmap\n",
    "    heatmap = cv2.applyColorMap(np.uint8(255 * cam), cv2.COLORMAP_JET)\n",
    "    \n",
    "    # Overlay heatmap on original image\n",
    "    overlayed = cv2.addWeighted(img, 0.7, heatmap, 0.3, 0)\n",
    "    return overlayed\n",
    "\n",
    "# 5. Custom Callback for Tracking Layer Activations\n",
    "class FeatureVisualizationCallback(keras.callbacks.Callback):\n",
    "    def __init__(self, validation_data, layer_names, output_dir='feature_viz', freq=2):\n",
    "        super(FeatureVisualizationCallback, self).__init__()\n",
    "        self.validation_data = validation_data\n",
    "        self.layer_names = layer_names\n",
    "        self.output_dir = output_dir\n",
    "        self.freq = freq\n",
    "        if not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir)\n",
    "            \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if (epoch + 1) % self.freq != 0:\n",
    "            return\n",
    "            \n",
    "        # Get a sample batch\n",
    "        x_val, y_val = next(self.validation_data)\n",
    "        \n",
    "        # Create a model to output activations for each layer\n",
    "        layer_outputs = [self.model.get_layer(name).output for name in self.layer_names]\n",
    "        activation_model = Model(inputs=self.model.input, outputs=layer_outputs)\n",
    "        \n",
    "        # Get activations\n",
    "        activations = activation_model.predict(x_val)\n",
    "        \n",
    "        # Visualize activations for each layer\n",
    "        for i, layer_name in enumerate(self.layer_names):\n",
    "            # Create output directory for this layer\n",
    "            layer_dir = os.path.join(self.output_dir, f\"{layer_name}_epoch{epoch+1}\")\n",
    "            if not os.path.exists(layer_dir):\n",
    "                os.makedirs(layer_dir)\n",
    "                \n",
    "            # Get layer activations\n",
    "            layer_activation = activations[i]\n",
    "            \n",
    "            # Visualize feature maps\n",
    "            plt.figure(figsize=(16, 16))\n",
    "            features_per_row = 8\n",
    "            n_features = min(64, layer_activation.shape[-1])\n",
    "            n_rows = n_features // features_per_row\n",
    "            \n",
    "            for j in range(n_features):\n",
    "                plt.subplot(n_rows, features_per_row, j+1)\n",
    "                plt.imshow(layer_activation[0, :, :, j], cmap='viridis')\n",
    "                plt.axis('off')\n",
    "                \n",
    "            plt.tight_layout()\n",
    "            plt.savefig(os.path.join(layer_dir, f\"feature_maps.png\"))\n",
    "            plt.close()\n",
    "            \n",
    "            # For the first sample image, also generate Grad-CAM for the top predicted class\n",
    "            if i == len(self.layer_names) - 1:  # Only do this for the last layer\n",
    "                predicted_class = np.argmax(self.model.predict(x_val[0:1]))\n",
    "                cam = generate_gradcam(self.model, x_val[0:1], layer_name, predicted_class)\n",
    "                \n",
    "                # Reshape CAM to image dimensions\n",
    "                cam_resized = cv2.resize(cam, (img_width, img_height))\n",
    "                \n",
    "                # Save CAM heatmap\n",
    "                plt.figure(figsize=(8, 8))\n",
    "                plt.imshow(cam_resized)\n",
    "                plt.colorbar()\n",
    "                plt.tight_layout()\n",
    "                plt.savefig(os.path.join(layer_dir, f\"gradcam_class{predicted_class}.png\"))\n",
    "                plt.close()\n",
    "\n",
    "# 6. DeepDream Visualization Callback\n",
    "def deepdream(model, img_array, layer_name, iterations=20, step=0.01):\n",
    "    \"\"\"Create a DeepDream image by maximizing activations\"\"\"\n",
    "    # Create a model that outputs the target layer's activations\n",
    "    feature_extractor = Model(inputs=model.input, outputs=model.get_layer(layer_name).output)\n",
    "    \n",
    "    # Define the loss (maximize activations)\n",
    "    def calculate_loss(img):\n",
    "        activation = feature_extractor(img)\n",
    "        return -tf.reduce_mean(activation)\n",
    "    \n",
    "    # Gradient ascent step\n",
    "    @tf.function\n",
    "    def gradient_ascent_step(img, learning_rate):\n",
    "        with tf.GradientTape() as tape:\n",
    "            tape.watch(img)\n",
    "            loss = calculate_loss(img)\n",
    "        \n",
    "        # Calculate gradients\n",
    "        grads = tape.gradient(loss, img)\n",
    "        # Normalize gradients\n",
    "        grads = tf.math.l2_normalize(grads)\n",
    "        # Apply gradients\n",
    "        img += learning_rate * grads\n",
    "        return loss, img\n",
    "    \n",
    "    # Start with the input image\n",
    "    dream_img = tf.convert_to_tensor(img_array)\n",
    "    \n",
    "    # Perform gradient ascent\n",
    "    for i in range(iterations):\n",
    "        loss, dream_img = gradient_ascent_step(dream_img, step)\n",
    "    \n",
    "    # Return the final image\n",
    "    return deprocess_image(dream_img.numpy())\n",
    "\n",
    "class DeepDreamVisualizationCallback(keras.callbacks.Callback):\n",
    "    def __init__(self, test_img_path, layers, output_dir='deepdream_viz', freq=5):\n",
    "        super(DeepDreamVisualizationCallback, self).__init__()\n",
    "        self.test_img = preprocess_image(test_img_path)\n",
    "        self.layers = layers\n",
    "        self.output_dir = output_dir\n",
    "        self.freq = freq\n",
    "        if not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir)\n",
    "            # Save original image for reference\n",
    "            original_img = image.load_img(test_img_path, target_size=(299, 299))\n",
    "            original_img.save(os.path.join(output_dir, 'original_image.jpg'))\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if (epoch + 1) % self.freq != 0:\n",
    "            return\n",
    "            \n",
    "        epoch_dir = os.path.join(self.output_dir, f\"epoch_{epoch+1}\")\n",
    "        if not os.path.exists(epoch_dir):\n",
    "            os.makedirs(epoch_dir)\n",
    "            \n",
    "        for layer_name in self.layers:\n",
    "            print(f\"Generating DeepDream for layer {layer_name} at epoch {epoch+1}\")\n",
    "            try:\n",
    "                # Generate DeepDream for this layer\n",
    "                dream_img = deepdream(\n",
    "                    self.model, \n",
    "                    self.test_img.copy(), \n",
    "                    layer_name,\n",
    "                    iterations=15  # Keep it reasonably fast for monitoring\n",
    "                )\n",
    "                \n",
    "                # Save visualization\n",
    "                Image.fromarray(dream_img).save(os.path.join(epoch_dir, f\"{layer_name}.jpg\"))\n",
    "            except Exception as e:\n",
    "                print(f\"Error generating DeepDream for layer {layer_name}: {e}\")\n",
    "\n",
    "# Initialize the base model\n",
    "base_model = InceptionV3(weights='imagenet', include_top=False)\n",
    "\n",
    "# Add a global spatial average pooling layer\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "# Add a fully-connected layer\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "\n",
    "# Add a final output layer with softmax for classification\n",
    "predictions = Dense(train_generator.num_classes, activation='softmax')(x)\n",
    "\n",
    "# Create the main model\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Select a representative flower image for visualization\n",
    "# You should replace this with an actual path to a flower image\n",
    "sample_img_path = os.path.join(train_dir, os.listdir(train_dir)[0], os.listdir(os.path.join(train_dir, os.listdir(train_dir)[0]))[0])\n",
    "print(f\"Using sample image for visualizations: {sample_img_path}\")\n",
    "\n",
    "# Setup callbacks\n",
    "monitor_layers = ['mixed3', 'mixed5', 'mixed7', 'mixed9']\n",
    "\n",
    "feature_viz_callback = FeatureVisualizationCallback(\n",
    "    validation_generator,\n",
    "    monitor_layers,\n",
    "    output_dir='feature_viz',\n",
    "    freq=2\n",
    ")\n",
    "\n",
    "deepdream_callback = DeepDreamVisualizationCallback(\n",
    "    sample_img_path,\n",
    "    monitor_layers,\n",
    "    output_dir='deepdream_viz',\n",
    "    freq=5\n",
    ")\n",
    "\n",
    "# Regular training callbacks\n",
    "checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
    "    'flower_model_checkpoint_{epoch:02d}.h5',\n",
    "    save_best_only=True,\n",
    "    monitor='val_accuracy'\n",
    ")\n",
    "\n",
    "reduce_lr_callback = keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,\n",
    "    patience=3,\n",
    "    min_lr=1e-6\n",
    ")\n",
    "\n",
    "callbacks = [\n",
    "    feature_viz_callback,\n",
    "    deepdream_callback,\n",
    "    checkpoint_callback,\n",
    "    reduce_lr_callback\n",
    "]\n",
    "\n",
    "# ----- TRAINING PROCESS -----\n",
    "\n",
    "# STEP 1: Train only the top layers with all base model layers frozen\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), \n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(\"PHASE 1: Training top layers only...\")\n",
    "history_1 = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // batch_size,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples // batch_size,\n",
    "    epochs=5,\n",
    "    callbacks=callbacks\n",
    ")\n",
    "\n",
    "# STEP 2: Progressive Layer Unfreezing - One block at a time\n",
    "# Get all the mixed layer names to use as reference points\n",
    "mixed_layers = [layer.name for layer in base_model.layers if 'mixed' in layer.name]\n",
    "mixed_layers.sort()  # Sort in ascending order from bottom to top\n",
    "\n",
    "histories = [history_1]  # Keep track of training history\n",
    "\n",
    "# Define the progressive unfreezing schedule - starting from the top\n",
    "unfreezing_schedule = [\n",
    "    mixed_layers[-1],  # mixed10\n",
    "    mixed_layers[-2],  # mixed9\n",
    "    mixed_layers[-3],  # mixed8\n",
    "    mixed_layers[-4],  # mixed7\n",
    "]\n",
    "\n",
    "# Learning rate schedule - decrease as we unfreeze deeper layers\n",
    "lr_schedule = [5e-4, 2e-4, 1e-4, 5e-5]\n",
    "\n",
    "# Progressively unfreeze layers and train\n",
    "for phase, (target_layer, lr) in enumerate(zip(unfreezing_schedule, lr_schedule), start=2):\n",
    "    print(f\"\\nPHASE {phase}: Unfreezing layers from {target_layer} onwards...\")\n",
    "    \n",
    "    # Reset all layers to trainable\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = True\n",
    "    \n",
    "    # Then freeze everything before the target layer\n",
    "    target_idx = [i for i, layer in enumerate(base_model.layers) if layer.name == target_layer][0]\n",
    "    for layer in base_model.layers[:target_idx]:\n",
    "        layer.trainable = False\n",
    "        \n",
    "    # Count trainable parameters\n",
    "    trainable_count = np.sum([K.count_params(w) for w in model.trainable_weights])\n",
    "    non_trainable_count = np.sum([K.count_params(w) for w in model.non_trainable_weights])\n",
    "    print(f\"Trainable parameters: {trainable_count:,}\")\n",
    "    print(f\"Non-trainable parameters: {non_trainable_count:,}\")\n",
    "    \n",
    "    # Alternative approach for feature diversity: Use custom regularizer instead of multiple outputs\n",
    "    if phase == 4:  # When we're unfreezing mixed7\n",
    "        print(\"Adding feature diversity regularization for mid-level layers...\")\n",
    "        \n",
    "        # Create a custom callback to monitor and encourage feature diversity\n",
    "        class FeatureDiversityCallback(keras.callbacks.Callback):\n",
    "            def __init__(self, layer_name='mixed7', weight=0.2):\n",
    "                super(FeatureDiversityCallback, self).__init__()\n",
    "                self.layer_name = layer_name\n",
    "                self.weight = weight\n",
    "                self.feature_model = None\n",
    "                \n",
    "            def on_train_begin(self, logs=None):\n",
    "                self.feature_model = Model(\n",
    "                    inputs=self.model.input,\n",
    "                    outputs=self.model.get_layer(self.layer_name).output\n",
    "                )\n",
    "                \n",
    "            def on_batch_end(self, batch, logs=None):\n",
    "                if batch % 10 != 0:  # Only apply every 10 batches to save computation\n",
    "                    return\n",
    "                    \n",
    "                # Get a batch of data\n",
    "                x_batch, _ = next(train_generator)\n",
    "                \n",
    "                # Get layer activations\n",
    "                with tf.GradientTape() as tape:\n",
    "                    layer_output = self.feature_model(x_batch)\n",
    "                    # Calculate diversity loss (negative std to maximize diversity)\n",
    "                    diversity_loss = -K.mean(K.std(layer_output, axis=-1))\n",
    "                    \n",
    "                # Calculate gradients of the diversity loss with respect to weights\n",
    "                trainable_weights = self.feature_model.trainable_weights\n",
    "                gradients = tape.gradient(diversity_loss, trainable_weights)\n",
    "                \n",
    "                # Apply gradients with a smaller weight\n",
    "                optimizer = self.model.optimizer\n",
    "                diversity_weight = self.weight * optimizer.learning_rate\n",
    "                \n",
    "                # Manually update weights to increase feature diversity\n",
    "                for w, g in zip(trainable_weights, gradients):\n",
    "                    if g is not None:\n",
    "                        new_w = w - diversity_weight * g\n",
    "                        w.assign(new_w)\n",
    "        \n",
    "        # Add our custom feature diversity callback\n",
    "        feature_diversity_cb = FeatureDiversityCallback(layer_name='mixed7', weight=0.2)\n",
    "        phase_callbacks = callbacks + [feature_diversity_cb]\n",
    "        \n",
    "        # Compile with standard loss (no multiple outputs)\n",
    "        model.compile(\n",
    "            optimizer=Adam(learning_rate=lr),\n",
    "            loss='categorical_crossentropy',\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "        \n",
    "        history_phase = model.fit(\n",
    "            train_generator,\n",
    "            steps_per_epoch=train_generator.samples // batch_size,\n",
    "            validation_data=validation_generator,\n",
    "            validation_steps=validation_generator.samples // batch_size,\n",
    "            epochs=5,\n",
    "            callbacks=phase_callbacks\n",
    "        )\n",
    "    else:\n",
    "        # Standard training for other phases\n",
    "        model.compile(\n",
    "            optimizer=Adam(learning_rate=lr),\n",
    "            loss='categorical_crossentropy',\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "        \n",
    "        history_phase = model.fit(\n",
    "            train_generator,\n",
    "            steps_per_epoch=train_generator.samples // batch_size,\n",
    "            validation_data=validation_generator,\n",
    "            validation_steps=validation_generator.samples // batch_size,\n",
    "            epochs=5,\n",
    "            callbacks=callbacks\n",
    "        )\n",
    "    \n",
    "    # Save history for plotting\n",
    "    histories.append(history_phase)\n",
    "\n",
    "# STEP 3: Final Fine-tuning Phase - All Layers\n",
    "print(\"\\nPHASE FINAL: Fine-tuning all layers with very low learning rate...\")\n",
    "\n",
    "# Make all layers trainable for final tuning\n",
    "for layer in model.layers:\n",
    "    layer.trainable = True\n",
    "\n",
    "# Very low learning rate for final fine-tuning\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=1e-5),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "history_final = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // batch_size,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples // batch_size,\n",
    "    epochs=5,\n",
    "    callbacks=callbacks\n",
    ")\n",
    "\n",
    "histories.append(history_final)\n",
    "\n",
    "# Save the final fine-tuned model\n",
    "model.save('flower_finetuned_inceptionv3_enhanced.h5')\n",
    "\n",
    "# Function to plot combined training history\n",
    "def plot_training_history(histories):\n",
    "    # Combined histories\n",
    "    acc = []\n",
    "    val_acc = []\n",
    "    loss = []\n",
    "    val_loss = []\n",
    "    \n",
    "    # Combine histories - simplified since we're no longer using multiple outputs\n",
    "    for history in histories:\n",
    "        if 'accuracy' in history.history:\n",
    "            acc.extend(history.history['accuracy'])\n",
    "            val_acc.extend(history.history['val_accuracy'])\n",
    "            loss.extend(history.history['loss'])\n",
    "            val_loss.extend(history.history['val_loss'])\n",
    "    \n",
    "    epochs_range = range(len(acc))\n",
    "    \n",
    "    plt.figure(figsize=(15, 7))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "    plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "    plt.axvline(x=5, color='r', linestyle='--', label='Phase 1')\n",
    "    plt.axvline(x=10, color='g', linestyle='--', label='Phase 2')\n",
    "    plt.axvline(x=15, color='b', linestyle='--', label='Phase 3')\n",
    "    plt.axvline(x=20, color='m', linestyle='--', label='Phase 4')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs_range, loss, label='Training Loss')\n",
    "    plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "    plt.axvline(x=5, color='r', linestyle='--', label='Phase 1')\n",
    "    plt.axvline(x=10, color='g', linestyle='--', label='Phase 2')\n",
    "    plt.axvline(x=15, color='b', linestyle='--', label='Phase 3')\n",
    "    plt.axvline(x=20, color='m', linestyle='--', label='Phase 4')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('enhanced_training_history.png')\n",
    "    plt.show()\n",
    "\n",
    "# Plot the training history\n",
    "plot_training_history(histories)\n",
    "\n",
    "# Function to analyze which layers contain the most flower-specific features\n",
    "def analyze_flower_features(model, class_idx=None):\n",
    "    \"\"\"\n",
    "    Analyzes model layers to find those with the strongest flower feature activations\n",
    "    \n",
    "    Parameters:\n",
    "    - model: The trained model\n",
    "    - class_idx: Optional specific flower class to analyze\n",
    "    \n",
    "    Returns:\n",
    "    - Dictionary with layer rankings\n",
    "    \"\"\"\n",
    "    # Get a few flower images\n",
    "    flower_batch = next(train_generator)[0]\n",
    "    \n",
    "    # List of layers to analyze (focus on mixed layers)\n",
    "    layers_to_analyze = [layer.name for layer in model.layers if 'mixed' in layer.name]\n",
    "    \n",
    "    # Store results\n",
    "    layer_stats = {}\n",
    "    \n",
    "    # For each layer, measure activations\n",
    "    for layer_name in layers_to_analyze:\n",
    "        print(f\"Analyzing layer: {layer_name}\")\n",
    "        layer_model = Model(inputs=model.input, outputs=model.get_layer(layer_name).output)\n",
    "        \n",
    "        # Get activations for the batch\n",
    "        activations = layer_model.predict(flower_batch)\n",
    "        \n",
    "        # Calculate statistics\n",
    "        mean_activation = np.mean(activations)\n",
    "        max_activation = np.max(activations)\n",
    "        std_activation = np.std(activations)\n",
    "        \n",
    "        # Store results\n",
    "        layer_stats[layer_name] = {\n",
    "            'mean': float(mean_activation),\n",
    "            'max': float(max_activation),\n",
    "            'std': float(std_activation)\n",
    "        }\n",
    "    \n",
    "    # Sort layers by mean activation (higher is better for feature representation)\n",
    "    sorted_layers = sorted(layer_stats.items(), key=lambda x: x[1]['mean'], reverse=True)\n",
    "    \n",
    "    print(\"\\nLayers ranked by activation strength (higher mean = stronger flower features):\")\n",
    "    for i, (layer_name, stats) in enumerate(sorted_layers):\n",
    "        print(f\"{i+1}. {layer_name}: Mean={stats['mean']:.6f}, Max={stats['max']:.6f}, Std={stats['std']:.6f}\")\n",
    "    \n",
    "    return layer_stats\n",
    "\n",
    "# Analyze which layers contain the most flower-specific features\n",
    "print(\"\\nAnalyzing which layers contain the strongest flower feature representations...\")\n",
    "layer_stats = analyze_flower_features(model)\n",
    "\n",
    "print(\"\\nTraining complete! Model saved as 'flower_finetuned_inceptionv3_enhanced.h5'\")\n",
    "print(\"This model has been optimized for strong flower feature representations across layers.\")\n",
    "print(\"For DeepDream, recommend using the top layers from the analysis above.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cvai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
